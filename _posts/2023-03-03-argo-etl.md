---
layout: post
title: "Argo Events 와 Workflows 를 이용한 ETL"
description:
date: 2023-03-03
tags: [draft]
---

# Argo Events 와 Workflows 를 이용한 ETL

이 글은 쿠버네티스 환경에서 원본 데이터가 저장된 파일을 가져와 정리하는 효율적인 방법에 대해 소개한다.

컨테이너화와 쿠버네티스는 최근 IT 업계에서 매우 중요한 기술 중 하나이다. 컨테이너화는 애플리케이션을 빠르고 쉽게 배포할 수 있도록 해주며, 쿠버네티스는 컨테이너 오케스트레이션 툴로, 컨테이너를 쉽게 관리하고 스케일링하는 등의 기능을 제공한다.

ETL(Extract, Transform, Load)은 데이터 분석 및 처리를 위한 중요한 과정이다. 이 과정에서는 데이터를 추출하고, 변환하여 필요한 형식으로 가공한 다음, 로드하여 저장소에 저장하게 된다. 이러한 ETL 과정은 데이터 처리의 핵심이다.

Argo Events와 Workflows를 이용하면, 쿠버네티스 환경에서 ETL 과정을 자동화하고, 쉽게 관리할 수 있다. Argo Events를 사용하면, 다양한 이벤트 소스로부터 이벤트를 감지하고, Workflow를 시작할 수 있다. Workflow는 ETL 과정의 각 단계를 효율적으로 처리할 수 있도록 도와준다. 이러한 방식으로 Argo Events와 Workflows를 이용하면, 데이터 처리 과정을 자동화하고, 더욱 빠르고 정확하게 처리할 수 있다.

예를 들어, S3 버킷에 새로운 파일이 업로드되면, Argo Events는 이를 감지하고, 새로운 Workflow를 시작한다. Workflow는 파일을 추출하고, 필요한 변환을 수행한 다음, 데이터를 로드하여 저장소에 저장한다. 이러한 방식으로 Argo Events와 Workflows를 이용하면, ETL 과정을 더욱 효율적으로 처리할 수 있으며, 데이터 분석 및 처리 과정을 자동화할 수 있다.

이 글에서는 예제를 통해 위의 과정을 살펴보겠다. 먼저 필요한 개념 및 준비 과정부터 시작하겠다. 

![Argo Events Overview](/assets/2023-03-03-18-00-48.png)


## 준비 

> 이 글에서는 Linux 환경 호스트를 전제로 설명한다. 

### 쿠버네티스 환경

일단 쿠버네티스 환경이 필요한다. 쿠버네티스는 다양한 배포판이 있으나, 예제에서는 로컬에 minikube 가 설치된 것을 가정하고 진행하겠다. 설치 방법은 [이곳](https://minikube.sigs.k8s.io/docs/start/) 을 참고하기 바란다.

또한, 쿠버네티스 환경에 다양한 패키지를 설치하기 위해 패키지 매니저인 [Helm](https://helm.sh/) 의 설치가 필요하다.

### Argo Events 설치

> Argo Events 의 최신 버전은 다음 링크에서 확인할 수 있다.
> https://github.com/argoproj/argo-events/releases

여기서는 버전 1.7.6 을 기준으로 설명한다. Helm 을 통해 Argo 의 차트로 설치한다.

```
helm repo add argo https://argoproj.github.io/argo-helm
helm install argo/events
```

추가로 이어서 설명할 EventBus 의 설치가 필요하다.

```yaml
kubectl apply -f - <<EOF
apiVersion: argoproj.io/v1alpha1
kind: EventBus
metadata:
  name: default
spec:
  nats:
    native:
      # 최소 3개 이상
      replicas: 3
      # 인증 전략
      auth: none
EOF
```

### Argo Workflows 설치

> Argo Workflows 의 최신 버전은 다음 링크에서 확인할 수 있다.
> https://github.com/argoproj/argo-workflows/releases

여기서는 버전 3.4.5 를 기준으로 설명한다. Argo Workflows 는 CLI 명령과 컨트롤러 및 서버 설치로 나뉘는데, 먼저 다음과 같이 CLI 를 설치한다.

```bash
# Download the binary
curl -sLO https://github.com/argoproj/argo-workflows/releases/download/v3.4.5/argo-linux-amd64.gz

# Unzip
gunzip argo-linux-amd64.gz

# Make binary executable
chmod +x argo-linux-amd64

# Move binary to path
mv ./argo-linux-amd64 /usr/local/bin/argo

# Test installation
argo version
```

컨트롤러 및 서버는 Helm 을 통해 Bitnami 의 차트로 설치한다.

```bash
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install awf bitnami/argo-workflows --set auth.enabled=false --set postgresql.enabled=false
```

Argo Workflows UI 로그인을 위해 토큰이 필요하다. 최신 K8S 에서는 Service Account 에 기본 토큰이 없기에, 다음처럼 `kubernetes.io/service-account.name` 어노테이션이 있는 Secret 을 만들고 ,

```
kubectl apply -f - <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: awf-argo-workflows-server-secret
  annotations:
    kubernetes.io/service-account.name: awf-argo-workflows-server
type: kubernetes.io/service-account-token
EOF
```

잠시 후에 다음처럼 토큰을 얻을 수 있다. 

```
ARGO_TOKEN="Bearer $(kubectl get secret awf-argo-workflows-server-secret -o=jsonpath='{.data.token}' | base64 --decode)"
echo $ARGO_TOKEN
```

UI 페이지 접속을 위해서 다음과 같이 포트포워딩이 필요하다.

```
kubectl port-forward --namespace default svc/awf-argo-workflows-server 8046:80
```

웹브라우저에서 `http://localhost:8046` 주소로 접속하고, 얻어둔 토큰을 이용해 로그인하면 된다.

![Workflow UI](/assets/2023-03-08-13-25-40.png)

### 아티팩트 저장소 준비 

Argo Workflows 에서 아티팩트 (Artifact) 는 작업의 결과로 생성되는 리소스나 파일을 말한다. 작업간 결과물을 아티팩트의 형태로 공유할 수 있다. 

아티팩트를 사용하기 위해서는 먼저 [아티팩트 저장소 (Artifact Repository)](https://argoproj.github.io/argo-workflows/configure-artifact-repository/) 를 설정하여야 한다. S3, Azure Blob, HDFS 등 다양한 아티팩트 저장소 타입이 있는데, 여기서는 [MinIO](https://min.io/) 를 이용하겠다. 

앞에서와 마찬가지로 [Helm](https://helm.sh/) 을 통해 Bitnami 의 차트로 설치한다.

```
helm install minio bitnami/minio
```

설치 후 MinIO 루트유저의 이름과 암호는 다음과 같이 얻을 수 있다.
```
# MinIO 루트유저 이름
kubectl get secret --namespace default minio -o jsonpath="{.data.root-user}" | base64 -d
# MinIO 루트유저 암호 
kubectl get secret --namespace default minio -o jsonpath="{.data.root-password}" | base64 -d
```

이제 minikube 기준으로 다음처럼 MinIO UI 의 접속 URL 을 얻는다.
```
$ minikube service --url minio
😿  service default/minio has no node port
http://127.0.0.1:44337
http://127.0.0.1:43593
```

아래에 출력된 URL 로 접속한 후 앞에서 얻어둔 루트 유저 이름과 암호로 로그인한다. 

![MinIO Login](/assets/2023-03-08-13-45-51.png)

이후 `Create Bucket` 링크를 눌러 `my-bucket` 이라는 이름의 버킷을 만든다.

![Artifact Bucket](/assets/2023-03-08-13-46-51.png)

실제 워크플로우가 사용할 저장소는 [아티팩트 저장소 레퍼런스](https://argoproj.github.io/argo-workflows/artifact-repository-ref/) 로 설정하는데, 그것은 쿠버네티스의 `ConfigMap` 을 통해 만들어진다. 다음과 같이 실행하면 된다.

```yaml
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: artifact-repositories
  annotations:
    workflows.argoproj.io/default-artifact-repository: default-minio-repository
data:
  default-minio-repository: |
    s3:
      bucket: my-bucket
      endpoint: minio:9000
      insecure: true
      accessKeySecret:
        name: minio
        key: root-user
      secretKeySecret:
        name: minio
        key: root-password
EOF
```

모든 설치가 완료되었으면, 지금부터 Argo Events 및 Argo Workflows 의 기본 개념을 살펴보겠다. 

## Argo Events 소개 

전통적으로 많은 조직에서 특정 시간이되면 원본 데이터가 갱신된 것을 가정하고, 가져와 처리하는 방식을 많이 사용하였다. 이는 일견 단순해 보이나 문제점을 내포하고 있다. 특히 다음과 같은 경우에 문제가 크다:

- 지정 시간에 원본 파일이 존재하지 않거나 불완전한 경우
- 지정 시간에 ETL 된 파일의 내용이 갱신되어 다시 올라오는 경우
- 지정 시간의 ETL 작업 종료 후 추가 파일이 올라오는 경우

이런 문제가 빈번한 경우 대응을 위해 모니터링 및 수동 재작업을 실시하곤 하는데, 시간 및 인적 리소스가 소모가 크다.

문제를 근원적으로 해결하기 위해서는 원본 데이터가 올라오는 이벤트를 인식하고, 해당 이벤트 발생시 작업을 진행하는 이벤트 기반 (Event-Driven) 방식의 도입이 필요한다. 이렇게 하면 파일이 예상보다 늦게 올라오거나, 바뀐 내용으로 다시 올라오는 경우에도 자동으로 재작업이 진행되기 때문이다.

Argo Events 는 이러한 이벤트 기반 처리를 위한 훌륭한 툴로, 다음과 같은 구성 요소를 가진다.

### Event 와 EventSource

Argo Events에서 Event는 구체적인 이벤트를 의미하며, EventSource는 하나 이상의 Event 타입을 통해 고수준의 이벤트를 정의하는 역할을 한다. 

> 단일 이벤트만 가지는 이벤트소스의 경우, 그 이벤트 타입이 이벤트소스의 타입으로 불려지곤 한다.

아래와 같은 이벤트 타입이 있다:

- 달력
- 파일
- HTTP (웹훅)
- AWS S3, SNS, SQS
- 쿠버네티스 리소스
- Kafka
- GitHub / GitLab

> 이 외에도 다양한 타입이 있으며, 필요하다면 커스텀 이벤트소스를 만들 수 있다.
> https://argoproj.github.io/argo-events/eventsources/generic/

### Sensor 와 Trigger

Argo Events에서 Sensor는 자신이 의존하는 EventSource 에서 이벤트가 발생하면 자신에게 등록된 하나 이상의 Trigger를 활성화하는 역할을 한다. Trigger는 발생한 이벤트 매개변수와 환경 정보를 참고해 지정된 동작을 실행한다. 

> 단일 트리거만 가지는 센서의 경우, 그 트리거 타입이 센서의 타입으로 불려지곤 한다.

아래와 같은 트리거 타입이 있다:

- HTTP 
- Argo Workflows
- AWS Lambda
- 쿠버네티스 리소스
- Kafka 메시지
- 로그 (디버깅 용)

> 이 외에도 다양한 타입이 있으며, 필요하다면 커스텀 트리거를 만들 수 있다. 
> https://argoproj.github.io/argo-events/sensors/triggers/build-your-own-trigger/

하나의 Sensor가 하나 이상의 Trigger를 가질 수 있으며, 이를 통해 다양한 Workflow를 실행할 수 있다.

### EventBus

Argo Events 에서 EventBus 는 이벤트 소스를 센서로 전달해주는 커스텀 쿠버네티스 리소스이다. 그렇게 하기 위해 EventBus 는 네임스페이스 안에 만들어져야 한다. 

> 이벤트버스는 오픈소스 경량 메시지 브로커인 [NATS](https://docs.nats.io/) 를 이용해 구현되었다.

---

이제 HTTP 포스트를 통해서 워크플로우를 트리거하는 예제를 살펴보자.

아래는 웹훅 이벤트소스 파일 `webhook.yaml` 이다. 

```yaml
apiVersion: argoproj.io/v1alpha1
kind: EventSource
metadata:
  name: webhook
spec:
  service:
    ports:
      - port: 12000
        targetPort: 12000
  webhook:
    # 이벤트 소스는 하나 이상의 HTTP 서버를 띄울 수 있다.
    example:
      # HTTP 서버 포트
      port: "12000"
      # 리슨할 엔드포인트 
      endpoint: /example
      # 허용되는 HTTP 메소드
      method: POST
```

이를 이용해 다음처럼 웹훅 이벤트소스를 생성한다. 

```
kubectl apply -f webhook.yaml
```

아래는 로그 센서 파일 `log.yaml` 이다.

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Sensor
metadata:
  name: log
spec:
  dependencies:
  # 이 센서가 의존하는 이벤트 소스 
  - name: test-dep
    eventSourceName: webhook
    eventName: example
  triggers:
  - template:
      name: log-trigger
      log:
        intervalSeconds: 1        
```

이를 이용해 다음처럼 로그 센서를 생성한다. 

```
kubectl apply -f log.yaml
```

이제 다음과 같이 지금까지 생성된 리소스를 확인할 수 있다. 

```
$ kubectl get pods
NAME                                                 READY   STATUS    RESTARTS   AGE
aev-argo-events-controller-manager-b99485cdf-ql8z2   1/1     Running   0          5m38s
awf-argo-workflows-controller-75686d754d-msrbg       1/1     Running   0          2m19s
awf-argo-workflows-server-588d6686bb-6qc5z           1/1     Running   0          2m19s
eventbus-default-stan-0                              2/2     Running   0          4m5s
eventbus-default-stan-1                              2/2     Running   0          3m53s
eventbus-default-stan-2                              2/2     Running   0          3m51s
log-sensor-rp56d-f8b5b694-bs99c                      1/1     Running   0          9s
webhook-eventsource-cfkdt-7fc944c598-mxlb9           1/1     Running   0          71s
```

> 파드 이름에 임의의 문자열이 붙어있는데, 이 부분은 실제 실습에서 나오는 것으로 대체하자. 

웹훅 이벤트소스 `webhook-eventsource-cfkdt-7fc944c598-mxlb9` 파드와 로그 센서 `log-sensor-rp56d-f8b5b694-bs99c` 파드를 확인할 수 있다. 이벤트버스는 고가용성을 위해 3개 이상의 파드를 이용한다.

호스트에서 POST 메소드를 호출하기 위해 포트포워딩을 한다. 

```
kubectl port-forward $(kubectl get pod -l eventsource-name=webhook -o name) 12000:12000
```

이제 웹훅 이벤트를 발생시키면, 이벤트 -> 이벤트 소스 -> 이벤트버스 -> 센서 -> 트리거의 순으로 진행될 것이다. 확인을 위해 다음처럼 로그 센서 파드의 로그를 모니터링 한다.

```
kubectl logs -f log-sensor-rp56d-f8b5b694-bs99c
```

이제 다음처럼 엔드포인트로 POST 를 호출하면,
```
curl -d '{"message":"this is my first webhook"}' -H "Content-Type: application/json" -X POST http://localhost:12000/example
```

트리거가 실행된 것을 로그로 확인할 수 있다.

```
{"level":"info","ts":1678248798.7899067,"logger":"argo-events.sensor","caller":"log/log.go:46","msg":"{\"header\":{\"Accept\":[\"*/*\"],\"Content-Length\":[\"38\"],\"Content-Type\":[\"application/json\"],\"User-Agent\":[\"curl/7.68.0\"]},\"body\":{\"message\":\"this is my first webhook\"}}","sensorName":"log","triggerName":"log-trigger","triggerType":"Log",
...
```

## Argo Workflows 소개

Argo Workflows는 데이터 처리와 같은 일괄 처리 작업을 처리하기 위해 사용되는데, Argo Events가 감지한 이벤트를 실질적으로 처리하기 위한 워크플로우를 구성하게 된다.

워크플로우는 쿠버네티스의 Job 리소스와 비슷한 구성의 yaml 파일로 작성한다. 

### 단순한 워크플로우 예제와 주요 개념 

다음은 간단한 워크플로우의 예이다.

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: hello-world-  # 워크플로우 이름 생성용 접두어 
spec:
  # 사용할 템플릿을 정의 
  templates:
  - name: whalesay            # `whalesay` 템플릿 정의 
    container:
      image: docker/whalesay
      command: [cowsay]
      args: ["hello world"]   
  # 위 템플릿으로 시작
  entrypoint: whalesay        
```

위 파일을 `hello-world.yaml` 로 저장하고 다음처럼 CLI 를 통해 적용한다. 

```
argo submit --watch hello-world.yaml
```

`--watch` 는 워크플로우가 완료될 때까지 정보를 계속 표시한다. 

> 아래와 같이 `kubectl` 을 이용해도 된다.
> ```
> kubectl create -f hello-world.yaml
> ```

다른 에러가 없다면, 성공적으로 워크플로우가 만들어진 것이다. CLI 를 통해 확인할 수 있다. 

```
$ argo list

NAME                STATUS      AGE   DURATION   PRIORITY   MESSAGE
hello-world-lncsd   Succeeded   2m    30s        0
```

워크플로우 이름은 앞서 `generateName` 으로 기술한 `hello-world-` 뒤에 랜덤 문자열이 붙은 형태이다. 

Argo Workflows UI 페이지에서도 생성된 워크플로우 정보와 로그를 확인할 수 있다.

![Workflow Info](/assets/2023-03-08-13-38-35.png)

![Workflow logs](/assets/2023-03-08-13-39-05.png)

> 만약 UI 에서 워크플로우가 보이지 않는다면, NAMESPACE 란을 확인해보자.

위 예제에서 처럼 `templates` 블럭 아래에 하나 이상의 작업용 템플릿을 정의할 수 있다. 템플릿에는 모두 6가지 타입이 있는데, 위 예는 컨테이너 템플릿을 이용한 것이다. 템플릿 타입은 크게 정의용 템플릿과 호출용 템플릿으로 나뉜다.

### 정의 템플릿

정의 (Definition) 템플릿은 구체적인 작업을 정의하기 위해 사용된다.

#### Container 템플릿 

컨테이너 템플릿은 가장 자주 사용되는 타입으로, 쿠버네티스의 컨테이너 스펙 과 같은 구조를 가진다. 특정 컨테이너 이미지와 명령, 그리고 인자를 지정하여 실행할 수 있다. 

아래 템플릿은 `docker/whalesay` 이미지에서 `hello world` 를 인자로 `cowsay` 명령을 실행하는 예이다.

```yaml
- name: whalesay
  container:
    image: docker/whalesay
    command: [cowsay]
    args: ["hello world"]
```

#### Script 템플릿 

스크립트 템플릿은 컨테이너 템플릿을 편의상 포장한 것으로, 다른 스펙은 비슷하나 `source` 블럭에 직접 코드를 기입할 수 있다는 점이 다르다. 

다음은 파이썬 컨테이너 이미지에서 파이썬 코드로 랜덤값을 출력하는 예이다.

```yaml
- name: gen-random-int
  script:
    image: python:alpine3.6
    command: [python]
    source: |
      import random
      i = random.randint(1, 100)
      print(i)
```

실행 결과는 이후 템플릿에서 `{{tasks.<NAME>.outputs.result}}` 또는 `{{steps.<NAME>.outputs.result}}` 변수로 이용할 수 있다.

#### Resource 템플릿 

리소스 템플릿은 쿠버네티스 클러스터의 리소스로 직접 작업을 하는 타입이다. `get`, `create`, `apply`, `delete`, `replace`, `patch` 동작이 가능하다.

다음 예는 쿠버네티스의 `ConfigMap` 리소스를 생성한다.

```yaml
- name: k8s-owner-reference
  resource:
    action: create
    manifest: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        generateName: owned-eg-
      data:
        some: value
```

#### Suspend 템플릿

서스펜드 템플릿은 주어진 시간동안, 또는 수동 명령이 있을 때까지 실행을 멈추고 기다리는데 사용된다. CLI 의 `argo resume` 명령으로 재개할 수 있다.

```yaml
- name: delay
  suspend:
    duration: "20s"
```

### 호출 템플릿

호출 (Invocation) 템플릿은 다른 템플릿을 호출하여 실행 흐름을 구성한다. 각 호출은 다음과 같은 구성을 가진다.

```yaml
name:     # 자신의 이름
template: # 호출할 템플릿 
arguments: # 템플릿에 넘길 매개변수
  parameters:  # 실제 인자값
```

#### Steps 템플릿

하나 이상의 스텝으로 작업을 구성할 수 있다. 각 스텝은 호출의 리스트로 구성된다. 개별 스텝은 정의된 순서대로 실행되고, 스텝내의 호출은 병렬로 실행된다.

아래 예에서 `steps` 블럭 아래에 스텝이 기술되어 있다. `step1` 이 실행된 후, `step2a` 와 `step2b` 가 동시에 실행된다.

> 스텝 리스트인 `steps` 아래 호출 리스트가 기술되는 구조이기에 `- -` 로 표기된 것에 주의하자.

```yaml
- name: hello-hello-hello
  steps:
  - - name: step1
      template: prepare-data
  - - name: step2a
      template: run-data-first-half
    - name: step2b
      template: run-data-second-half
```

#### DAG 템플릿 

DAG (Directed Acyclic Graph) 는 *유향 비순환 그래프* 를 나타내는데, 워크플로우를 구성하는 하위 작업 (task) 들이 의존 관계 그래프로 구성될 때 유용하다. 

아래 예제처럼, 이러한 DAG 구조 템플릿 정의를 위해 `dag` 블럭을, 하부 과제의 의존 관계를 기술하기 위해 `depends` 블럭을 이용한다.

```yaml
- name: diamond
  dag:
    tasks:
    - name: A
      template: echo
    - name: B
      dependencies: [A]
      template: echo
    - name: C
      dependencies: [A]
      template: echo
    - name: D
      dependencies: [B, C]
      template: echo
```

예제는 다음과 같은 다이아몬드 구조를 가진다.

```  
    A
   / \
  B   C
   \ /
    D
```

그림에서 최종 스텝 D를 수행하기 위해, B 와 C 가 필요하고, B 와 C 가 수행되기 위해서는 A 가 먼저 수행되어야 한다.

이제 호출 템플릿을 이용하여 동작하는 예제를 살펴보겠다.

### 멀티 스텝 워크플로우 예제

다음은 정의된 템플릿을 한 번 이상 순차적으로, 또 동시에 호출하여 작업을 구성하는 예제이다. 이를 위해 `steps` 블럭을 이용해 템플릿을 정의하고 있다. 아래 내용을 `steps.yaml` 파일로 저장하자.

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: steps-
spec:
  templates:
  # 공통 템플릿 정의
  - name: whalesay
    # message 패러미터를 템플릿 입력으로
    inputs:
      parameters:
      - name: message
    container:
      image: docker/whalesay
      command: [cowsay]
      # 템플릿 입력을 명령 인자로 사용
      args: ["{{inputs.parameters.message}}"]

  # 공통 템플릿을 호출하는 멀티스텝 템플릿
  - name: hello-hello-hello
    steps:
    # 1. hello1
    - - name: hello1
        template: whalesay
        arguments:
          # 템플릿 인자
          parameters: [{name: message, value: "hello1"}]
    # 2. hello2a, hello2b
    - - name: hello2a
        template: whalesay
        arguments:
          # 템플릿 인자
          parameters: [{name: message, value: "hello2a"}]
      - name: hello2b
        template: whalesay
        arguments:
          # 템플릿 인자
          parameters: [{name: message, value: "hello2b"}]
  
  # 멀티 스텝 템플릿으로 시작
  entrypoint: hello-hello-hello
```

다음처럼 실행하면,

```
argo submit --watch steps.yaml
```

아래와 같은 출력이 나올 것이다.

```
Name:                steps-wk5m5
Namespace:           argo
ServiceAccount:      unset (will run with the default ServiceAccount)
Status:              Succeeded
Conditions:
 PodRunning          False
 Completed           True
Created:             Mon Mar 06 18:43:10 +0900 (30 seconds ago)
Started:             Mon Mar 06 18:43:10 +0900 (30 seconds ago)
Finished:            Mon Mar 06 18:43:40 +0900 (now)
Duration:            30 seconds
Progress:            3/3
ResourcesDuration:   18s*(1 cpu),18s*(100Mi memory)

STEP            TEMPLATE           PODNAME                          DURATION  MESSAGE
 ✔ steps-wk5m5  hello-hello-hello
 ├───✔ hello1   whalesay           steps-wk5m5-whalesay-1602185977  6s
 └─┬─✔ hello2a  whalesay           steps-wk5m5-whalesay-3712874914  9s
   └─✔ hello2b  whalesay           steps-wk5m5-whalesay-3696097295  6s
```

`hello1` 이 먼저 실행된 후, `hello2a` 와 `hello2b` 가 동시에 실행되는 것을 보여주는데, UI 에서 좀 더 확실히 확인할 수 있다. 

![Multi step](/assets/2023-03-06-18-46-24.png)

kubectl 로 보면 각 템플릿 호출마다 파드가 생성된 것을 확인할 수 있다.

```
$ kubectl get pods 
NAME                                   READY   STATUS      RESTARTS   AGE
argo-server-fb8f5967d-tlqs5            1/1     Running     0          3h54m
steps-wk5m5-whalesay-1602185977        0/2     Completed   0          6m1s
steps-wk5m5-whalesay-3696097295        0/2     Completed   0          5m51s
steps-wk5m5-whalesay-3712874914        0/2     Completed   0          5m51s
workflow-controller-78f7ffdf79-7rctb   1/1     Running     0          3h55m
```

> 어떤 파드가 어떤 호출에 속하는지는 파드 정보의 `Annotations` 블럭을 보면 알 수 있다. 예를 들면 아래와 같은 식이다.
> ```bash
> $ kubectl describe pod steps-wk5m5-whalesay-1602185977
> ...
> Annotations:
>   workflows.argoproj.io/node-name: steps-wk5m5[0].hello1
> ...
> ```

파드의 로그를 확인해보면 아래와 같이 기술된 매개변수로 공용 템플릿이 호출된 것을 알 수있다.

`hello1` 호출 로그
```
 _________
< hello1 >
 ---------
    \
     \
      \
                    ##        .
              ## ## ##       ==
           ## ## ## ##      ===
       /""""""""""""""""___/ ===
  ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ /  ===- ~~~
       \______ o          __/
        \    \        __/
          \____\______/
```
`hello2a` 호출 로그
```
 _________
< hello2a >
 ---------
    \
     \
      \
                    ##        .
              ## ## ##       ==
           ## ## ## ##      ===
       /""""""""""""""""___/ ===
  ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ /  ===- ~~~
       \______ o          __/
        \    \        __/
          \____\______/
```
`hello2b` 호출 로그
```
 _________
< hello2b >
 ---------
    \
     \
      \
                    ##        .
              ## ## ##       ==
           ## ## ## ##      ===
       /""""""""""""""""___/ ===
  ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ /  ===- ~~~
       \______ o          __/
        \    \        __/
          \____\______/
```

### DAG 워크플로우 예제

아래는 앞서 본 다이아몬드 구조 워크플로우의 예이다. 멀티 스텝보다 복잡한 트리 구조를 표현할 수 있다. DAG 구조 템플릿 정의를 위해 `dag` 블럭을, 호출의 의존 관계를 기술하기 위해 `depends` 블럭을 이용한다. 내용을 `dag-diamond.yaml` 파일로 저장한다.

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: dag-diamond-
spec:
  entrypoint: diamond
  templates:
  # 공통 템플릿 정의
  - name: echo
    inputs:
      parameters:
      - name: message
    container:
      image: alpine:3.7
      command: [echo, "{{inputs.parameters.message}}"]
  # 공통 템플릿을 호출하는 멀티 스텝 템플릿 정의
  - name: diamond
    dag:
      tasks:
      - name: A
        template: echo
        arguments:
          parameters: [{name: message, value: A}]
      - name: B
        depends: "A"       # A 에 의존
        template: echo
        arguments:
          parameters: [{name: message, value: B}]
      - name: C
        depends: "A"       # A 에 의존
        template: echo
        arguments:
          parameters: [{name: message, value: C}]
      - name: D
        depends: "B && C"  # B 와 C 에 의존
        template: echo
        arguments:
          parameters: [{name: message, value: D}]
```

> 하나 이상의 선행 호출을 의존하는 D 의 경우 `B && C` 형태로 기술하였다.
> 의존 관계를 위해 다양한 논리 연산을 지원하는 데, 자세한 것은 [공식 페이지](https://argoproj.github.io/argo-workflows/enhanced-depends-logic/) 를 참고하자. 

다음처럼 실행하면,

```
argo submit --watch dag-diamond.yaml
```

아래와 같은 출력이 나올 것이다.

```
Name:                dag-diamond-d6xfs
Namespace:           argo
ServiceAccount:      unset (will run with the default ServiceAccount)
Status:              Succeeded
Conditions:
 PodRunning          False
 Completed           True
Created:             Tue Mar 07 12:00:27 +0900 (40 seconds ago)
Started:             Tue Mar 07 12:00:27 +0900 (40 seconds ago)
Finished:            Tue Mar 07 12:01:07 +0900 (now)
Duration:            40 seconds
Progress:            4/4
ResourcesDuration:   16s*(1 cpu),16s*(100Mi memory)

STEP                  TEMPLATE  PODNAME                            DURATION  MESSAGE
 ✔ dag-diamond-d6xfs  diamond
 ├─✔ A                echo      dag-diamond-d6xfs-echo-1891072275  8s
 ├─✔ B                echo      dag-diamond-d6xfs-echo-1907849894  4s
 ├─✔ C                echo      dag-diamond-d6xfs-echo-1924627513  4s
 └─✔ D                echo      dag-diamond-d6xfs-echo-1941405132  4s
```

이 출력 만으로는 DAG의 구조를 파악하기가 쉽지 않다. UI 에서 살펴보면 확실히 파악할 수 있다.

![Diamond DAG](/assets/2023-03-07-12-03-18.png)

다음으로는 작업들간 결과물을 주고 받는 방법을 알아보겠다.

### 아티팩트 워크플로우 예제

다음 예제는 멀티 스텝 형태로, 첫 스텝 `generate-artifact` 에서 아티팩트를 생성하고, 다음 스텝 `print-message` 에서 생성된 아티팩트를 이용하도록 구현되어 있다. 내용을 `artifact-passing.yaml` 로 저장하자.

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: artifact-passing-
spec:
  entrypoint: artifact-example
  templates:
  # 아티팩트 생성용 정의 템플릿
  - name: whalesay
    container:
      image: docker/whalesay:latest
      command: [sh, -c]
      args: ["sleep 1; cowsay hello world | tee /tmp/hello_world.txt"]
    # 출력으로 사용할 아티팩트
    outputs:
      artifacts:
      # 생성된 /tmp/hello_world.txt 파일에서 hello-art 아티팩트를 생성
      # (아티팩트는 파일뿐만 아니라 디렉토리 형태도 가능)
      - name: hello-art             # 출력 아티팩트 이름 
        path: /tmp/hello_world.txt  # 출력 아티팩트 파일

  # 아티팩트 프린트용 정의 템플릿
  - name: print-message
    # 입력으로 사용할 아티팩트
    inputs:
      artifacts:
      # 전달받은 아티팩트를 풀어서 /tmp/message 파일에 저장
      - name: message       # 입력 아티팩트 이름 
        path: /tmp/message  # 입력 아티팩트 파일
    container:
      image: alpine:latest
      # 아티팩트에서 풀린 파일 프린트
      command: [sh, -c]
      args: ["cat /tmp/message"]

  # 멀티스텝 호출 템플릿
  - name: artifact-example
    steps:
    # 1. 아트팩트 생성 호출
    - - name: generate-artifact
        template: whalesay
    # 2. 아티팩트 프린트 호출
    - - name: consume-artifact
        template: print-message
        arguments:
          artifacts:
          # 생성 호출에서 생성된 hello-art 아티팩트를 프린트 템플릿의 입력 아티팩트로 바인딩 
          - name: message
            from: "{{steps.generate-artifact.outputs.artifacts.hello-art}}"
```

다음처럼 실행하면,

```
argo submit --watch artifact-passing.yaml  
```

다음과 같은 출력이 나올 것이다.

```
Name:                artifact-passing-j4rfp
Namespace:           default
ServiceAccount:      unset (will run with the default ServiceAccount)
Status:              Succeeded
Conditions:
 PodRunning          False
 Completed           True
Created:             Wed Mar 08 14:06:55 +0900 (31 seconds ago)
Started:             Wed Mar 08 14:06:55 +0900 (31 seconds ago)
Finished:            Wed Mar 08 14:07:26 +0900 (now)
Duration:            31 seconds
Progress:            2/2
ResourcesDuration:   12s*(1 cpu),12s*(100Mi memory)

STEP                       TEMPLATE          PODNAME                                          DURATION  MESSAGE
 ✔ artifact-passing-j4rfp  artifact-example
 ├───✔ generate-artifact   whalesay          artifact-passing-j4rfp-whalesay-1776896446       5s
 └───✔ consume-artifact    print-message     artifact-passing-j4rfp-print-message-4173331406  8s
```

UI 에서 살펴보면 생성된 아티팩트 `hello-art.tgz` 를 확인할 수 있다.

![Artifact Flow](/assets/2023-03-08-14-08-01.png)

> 아티팩트는 기본적으로 `tar+gzip` 파일로 압축되는데, 필요에 따라 압축 설정을 바꿀 수 있다.

## 로컬 파일 ETL 예제

## S3 파일 ETL 예제 

## FTP 파일 ETL 예제 

### 커스텀 센서 만들기

## 예외적인 상황 대응

- 파일이 지연되어 올라오는 경우
- 파일이 불완전하게 올라온 후, 이후 완전한 파일이 다시 올라오는 경우


## 끝으로

### 참고 링크

https://argoproj.github.io/argo-events/
https://github.com/argoproj/argo-events
https://argoproj.github.io/argo-workflows/
https://github.com/argoproj/argo-workflows
https://coffeewhale.com/kubernetes/workflow/argo/2020/02/14/argo-wf/
