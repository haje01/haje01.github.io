---
layout: post
title: 이탈 예측을 어떻게 할 것인가?
description:
date: 2020-02-07
tags: [idea, draft]
---

예전에 게임 유저 이탈 예측을 시도해 보았는데, 성과가 썩 좋지는 않았다. 유저 이탈은 외부 요인 등으로 인해 성능에 한계가 있지만, 아래의 사항을 고려하여 다시 시도해보려 한다.

## 개선할 것

### 유저 플레이 빈도 고려

저번에는 매일 플레이하는 유저나, 주말에만 플레이하는 유저나 같은 모델을 사용했는데, 이 부분이 개선이 필요한 것 같다.

일반적으로 초기에는 열성적으로 매일 플레이하던 유저도 점점 접속일 간격이 벌어지면서 결국 이탈하는 경향이 있다. 반면 매일 플레이하다 갑자기 이탈하는 유저도 존재하는데, 이런 경우들을 구분해서 모델을 만들고 싶다.

### 피처 합성 및 HPO 활용

저번에는 수작업된 피처들과, 적당히 휴리스틱으로 선택한 초모수로 훈련하였다. 최근에 [Featuretools](https://www.featuretools.com) 등의 자동 피처 합성기와 Dask 나 Ray 클러스터를 이용한 초모수 최적화(Hyper-parameter Optimization) 테크닉을 활용해보려 한다. 얼마 안되는 피처에서 대충 설정한 초모수 보다는 좋은 결과가 나올 것으로 기대한다.

## 플레이 빈도별 유저 군집화

* 유저를 단위 기간 당 플레이한 날의 평균에 따라 다음과 같은 군집으로 분류한다. (단위 기간 U = 7 (일주일) 이고, 단위 기간 한계 접속일 수 (아래에서 설명) k^mar = 1 인 경우)
* 군집 분류:
  * g^1 - 단위 기간당 접속일이 1 일인 유저군
  * g^2 - 단위 기간당 접속일이 2 일인 유저군
  * ...
  * g^7 - 단위 기간당 접속일이 7 일인 유저군

* 단위 기간 당 최소 접속일 수 미만 (위의 경우 일주일에 한 번 미만) 으로 플레이하는 유저는 학습 및 예측 대상으로 하지 않는다.
* 일반적으로 g^7 군의 유저는 이탈 확률이 낮고, g^1 군의 유저는 높을 것으로 추정되며 징후도 다를 것이기에 각 군집 별로 데이터를 모으고 학습한다.
* 시간이 경과됨에 따라 유저가 속한 군집도 바뀔 것이기에, 기간 별로 유저의 군집을 평가해 사용한다.

### 유저 군집의 활용

* 유저 군집별로 학습 / 예측 데이터를 준비한다.
* 유저 군집별로 예측 모델을 학습한다.

## 용어와 개념

* *예측일 (target_day, t)* : 이탈을 예측하는 날자
* *기간 (term, T)* : 시작일 (begin, b) 부터 종료일 (end, e) 까지의 범위를 지칭. 종료일 (e) 는 포함되지 않는다.
* *단위 기간* (unit_term, U) : 사용하는 기간의 단위. 보통 U = 7, 즉 일주일로 한다.
* *기간 일 수 (days, d)* : 기간 내 날자의 수
* *접속일 (play)* : 유저가 플레이한 날
* *결석일 (absent)* : 유저가 플레이하지 않은 날
* *마지막 접속일 (last_play, l)* : 유저의 기간 내 마지막 접속일
* *결석일 수 (absents, a)* : 유저가 기간 동안 결석한 일 수
  * 기간 내 마지막 접속일에서 기간의 마지막 날까지 결석일을 센다.
  * 예로, 마지막 날 e = 2020-02-10 인 기간에서 5 일을 마지막 접속일 (l = 2020-02-15) 로 이후 결석하고 있다면, 결석일 수 a = 4 가 된다

$$a = e - l - 1$$

* *기간 접속일 수 (plays, p)* : 기간 내 유저가 접속한 일 수
  * 주어진 기간 동안 4번 접속한 경우 $p = 4$

* *단위 기간당 접속일 수 (unit_plays, k)* : 기간 내 유저의 접속일 수를 단위 기간으로 계산한 것.
  * 예로, 단위 기간이 일주일 U = 7 일때 유저가 기간일 수 d = 14 동안 접속일 p = 2 인 경우 k = 1
  * 이 값으로 유저가 속한 군집을 결정하게 된다.
  * 최대값은 U 와 같다.

$$k = \lceil \frac {p} {d} \rceil \times U$$

* *단위 기간 한계 접속일 수 (unit_margin_play, k^mar)* : 단위 기간당 접속일 수 (k) 의 한계값. 유저의 단위 기간당 접속일이 이 값 미만이면 학습 및 예측에서 제외한다. (초모수)
  * 기대 이익에 맞도록 적절하게 선택

* *접속 주기 (play_freq, f)* : 유저가 몇 일마다 접속하는지의 값. 기간 일 수 (d) 와 접속일 수 (p) 로 계산

$$f = \lceil \frac {d} {p} \rceil = \lceil \frac {U} {k} \rceil $$

* *최대 접속 주기 (max_play_freq, f^max)* : 접속 주기의 최대값. 단위 기간 (U) 및 한계 접속일 수 (k^mar) 로 계산.
  * 예로, 단위 기간 U = 7 이고 한계 접속일 수 k^mar = 3 이면, f^max = 2.3 이 된다.

$$f^{max} = \frac {U} {k^{mar}} $$

<!-- * *최대 단위 기간당 접속일 수 (max_unit_plays, k^max)* : 단위 기간당 접속일 중 가장 큰 값. 최소 접속 주기의 역

$$k^{max} = \frac {7} {min(f)}$$ -->

* *군집 (group, g^k)* : 접속 빈도에 따른 학습 데이터와 예측 모델 분류에 사용. 각 유저의 단위 기간당 접속일 수 (k) 로 결정된다.
  * 예로, 단위 기간당 접속일이 3 일인 유저는 g^3 군집이다.

* *군집 집합 (group set, G)* : 전체 군집의 모임

$$ G = \{g^k \vert k \in \mathbb Z \land k^{mar} \leq k \leq U \}$$

 * 단위 기간 (U) 과 단위 기간 한계 접속일 수 (k^mar) 에 의해 군집 집합이 결정된다. 예로, U = 7 이고 k^mar = 3 인 경우 군집 집합은 다음과 같다:

$$ G = \{ g^3, g^4, g^5, g^6, g^7 \}$$

* *유효 접속일 수 (effect_plays, e_p)* : 기간 종료일 기준으로 몇 번째 최근 접속일 데이터까지를 사용할지를 나타냄 (초모수)
  * 예로 e_p = 4 라는 것은, 유저의 마지막 접속일부터 최근 4 접속일 까지의 데이터를 사용하겠다는 뜻이다.
  * 유저의 군집 결정, 학습 및 예측에 필요한 데이터 범위 결정에 사용된다.
  * 이 값이 클 수록 모델 성능이 향상될 수 있으나, 많은 데이터가 필요하고 개념 표류 (Concept Drifting) 가 발생할 수 있다.


* *유효 데이터 일 수 (effect_data_days, e_d)* : 유저별로 유효 접속일 수에 해당하는 데이터 수집에 필요한 일 수.
  * 접속 주기 (f) 와 유효 접속일 수 (e_p) 로 계산
  * 예로, 접속 주기 f = 2 인 유저에 대해 유효 접속일 수 e_p = 4 인 데이터를 모으려면 e_d = 8 일치 데이터를 확보해야 한다.

$$e_d = f \times e_p$$

* *최대 유효 데이터 일 수 (max_effect_data_days, e_d^max)* : 모든 대상 유저의 유효 접속일 수 중 가장 큰 값. 전체 대상 유저에 대한 유효 데이터를 확보하려할 때 사용.
  * 최대 접속 주기 (f^max) 와 유효 접속일 수 (e_p) 로 계산한다.
  * 예를 들어 U = 7, k^mar = 3 이고 e_p = 4 인 경우, e_d^max = ceil(7/3) x 4 = 12 로, 적어도 12 일분 전체 데이터를 확보해야 모든 대상 유저의 유효 접속일 수 데이터가 보장된다.

$$e_d^{max} = \lceil f^{max} \times {e_p} \rceil $$

* *접속 예정일 (due_play_day, q)* : 기간 내 유저의 마지막 참석일 이후 예상되는 다음 접속일. 마지막 접속일 (l) 과 접속 주기 (f) 로 계산.

$$q = l + f$$

* *결석률 (absent_rate, r)* : 유저의 접속 예정일 (q) 이후, 예측일 (t) 까지 결석일 수를 접속 주기에 대한 비율로 나타낸 것 (0 이상).
  * 다양한 접속 주기의 유저들의 결석 정도를 일관성있게 평가하기 위한 값이다.
  * 예로, 접속 주기 f = 3 일인 유저가, 6일 동안 결석했다면 (a = 6), 결석율 r = 2.0

$$r = max \left( \frac {a} {f}, 0 \right) $$

* *이탈 결석률 (churn_absent_rate, r_c)* : 유저의 결석률이 이 값보다 크거나 같으면 이탈로 판정. 너무 늦지 않고, 너무 민감하지도 않도록 설정 (초모수)
  * 예로, r_c = 2 이면 두 번의 접속 주기만큼 결석하면 이탈이라는 뜻

* *이탈 판정일 수 (churn_decide_days, c_d)* : 유저의 이탈 판정에 필요한 최소 날자 수. 이탈 결석률 (r_c) 과 접속 주기 (f) 에서 계산
  * 예로, 접속 주기 f = 2 일인 유저에 대해 이탈 결석률 r_c = 3 으로 하면, 이탈 판정에 필요한 날자는 마지막 접속일 후 6 일이 된다.

$$c_d = \lceil r_c \times f \rceil $$

* *최대 이탈 판정일 수 (max_churn_decide_days, c^max)* : 모든 이탈 판정일 수 중 가장 큰 값. 최대 접속 주기 (f^max) 와 이탈 결석률 (r_c) 로 계산
  * 예로 최대 접속 주기 f^max = 2.3 이고 이탈 결석률 r_c = 3 이면 c^max = ceil(2.3 x 3) = 7

$$c^{max} = \lceil f^{max} \times r_c \rceil $$

## 피처

이탈 예측을 위한 피처는 대상 서비스 별로 다양할 것이나, 여기서는 온라인 및 모바일 게임을 위한 피처를 가정하였다.

유저의 행동 로그에서 이탈을 예측한다는 것은 시계열 예측으로 보아야 하겠다. 먼저 다음과 같은 유저별 피처를 일단위로 구성하고, 여기에서 시간 경과에 따른 경향을 피쳐화하겠다.

### 직접 피처들

직접 피처는 테이블이나 로그의 특정 필드에서 바로 구할 수 있는 피처를 말한다.

#### 계정 피처
* 플레이 시간
* 아이템 습득 수
* 아이템 거래 수
* 채팅 수
* 던전/퀘스트 수행 수
* 아이템 강화 성공/실패
* 결제 수

#### 캐릭터 피처
* 레벨 증가

### 합성된 피처들

수작업 미처에서 미처 발견하지 못한 피처가 이탈 예측의 중요한 변수가 될 수도 있다. 이에 예전에 소개한 Featuretools 의 [심층 피처 합성](https://haje01.github.io/2019/12/27/deep-feature-synthesis.html) 방식을 이용하여 합성된 피처들도 이용한다.

### 피처 필터링

수작업에 합성된 것까지 포함하면 굉장히 많은 피처를 다루게 될 것이다. 본격적인 모델 학습 전에 피처 필터링 단계를 통해 피처 수를 줄이는 것이 좋겠다.

## 데이터 준비

앞서 말한 개념과 피처를 통해 학습 및 예측을 위한 데이터를 준비하게 된다. 중요한 것은 *모든 유저가 대상은 아니라는 점* 이다. 게임 가입 후 적응하지 못하여 초기에 이탈했거나 비정기적으로 플레이하는 유저, 그리고 어뷰징 툴을 사용하는 등의 유저의 경우는 대상으로 하지 않는 것이 *기대 이익을 최대화하는 이탈 검출* 을 위해 바람직할 것이다.

### 학습 데이터

*학습 데이터 (learn_data, L)* 는 *유저별 일 단위 피처 (features, X)* 와 *라벨 (label, y)* 로 구성되며, 여기에서 각 군집별 학습 데이터가 만들어 진다.

#### 용어와 개념

* *학습 데이터 (learn_data, L_T 줄여서 L)* : 대상 기간 (T) 에 대한 학습 데이터. 줄여서 *학습 데이터* 로 부름.
* *학습 데이터 일 수 (learn_data_days, L_d)* : 기간 내 학습 데이터의 날자 수
  * 데이터는 많을 수록 좋으나, 개념 표류를 피하도록 적절한 L_d 설정 (초모수)
  * 적어도 이후 설명할 최소 학습 데이터 일 수 (L_d_min) 이상이어야 한다.

$$L_d \geq L_d^{min}$$

* *최소 학습 데이터 일 수 (min_learn_data_days, L_d^min)* : 학습 용 데이터는 군집 결정 및 이탈 판정이 가능해야하는데, 이를 위해 필요한 최소한의 데이터 날자 수.
  * 최대 유효 데이터 일 수 (e_d^max) 와 최대 이탈 판정일 수 (c^max) 의 합이다.
  * 예로, 최대 유효 데이터 일 수 e_d^max = 28 이고 최대 이탈 판정일 수 c^max = 14 이면 L_d^min 은 42 가 된다.

$$L_d^{min} = e_d^{max} + c^{max}$$

* *학습 데이터 시작일 (learn_data_begin, L_b)* : 학습 데이터의 시작 날자.
* *학습 데이터 종료일 (learn_data_end, L_e)* : 학습 데이터의 마지막 날자. 이어 설명할 예측 데이터 시작일 (P_b) 보다 작아야 함

$$ L_e < P_b $$

* 학습 데이터의 시작일은 학습 데이터 종료일 (L_e) 과 학습 데이터 일 수 (L_d) 로 결정

$$L_b = L_e - L_d$$

#### 군집 학습 데이터

앞에서 주간 접속일 수 (k) 로 유저의 군집을 배정하는 것을 살펴보았다. 이제 학습 데이터에서 *군집 학습 데이터 집합 (group_learn_data_set, O)* 을 다음과 같이 준비한다:

* 군집 집합 (G) 내 각 군집에 대해 각각의 군집 학습 데이터 (group_learn_data, o^k) 로 구성

$$O = \{ o^k \vert k \in \mathbb Z, k^{mar} \leq k \leq U\}$$

* 예로, U = 7 이고 k^mar = 3 인 경우 군집 학습 데이터 집합은 다음과 같다:

$$ O = \{ o^3, o^4, o^5, o^6, o^7 \}$$

* 같은 유저도 시간 경과에 따라 접속 주기가 달라질 수 있기에, 이어 설명할 수집 윈도우를 이용해 시기별 학습 데이터를 군집에 배정한다.
* 예 : 어떤 유저가 수집 윈도우 별로 g^5 -> g^3 -> g^1 순으로 군집이 변하다 이탈
  * 이 유저의 g^5 시기 데이터를 o^5 에 배정하고 비이탈로 라벨링
  * 이 유저의 g^3 시기 데이터를 o^3 에 배정하고 비이탈로 라벨링
  * 이 유저의 g^1 시기 데이터를 o^1 에 배정하고 이탈로 라벨링

* *수집 윈도우 (col_window, w)* : 유저의 학습 데이터를 순회하며 데이터를 수집하는 윈도우.
  * 데이터 양을 늘리고 군집에 맞는 데이터 수집을 위해 이용

* 수집 윈도우 내 데이터는 유효 데이터 일 수 (e_d) 의 데이터와 이탈 판정일 수 (c_d)의 데이터로 나뉜다.
  * 유효 데이터 일 수의 데이터는 학습에 사용되고, 이탈 판정일 수의 데이터는 라벨링에만 사용된다.

* *수집 윈도우 시작일 (col_window_begin, w_b)* : 특정 유저에 대한 윈도우 시작일. 유저의 기간 내 첫 접속일 부터 이어 설명할 윈도우 스텝만큼 증가한다.

* *수집 윈도우 종료일 (col_window_end, w_e)* : 수집 윈도우 시작일 부터 유효 데이터 일 수 및 이탈 판정일 수로 계산

$$w_e = w_b + e_d + c_d$$

* *수집 윈도우 스텝 (col_window_step, w_s)* : 윈도우의 진행 스텝.
  * 중복을 허용하되, 적정 수준을 유지하도록 유저의 유효 데이터 일 수 (e_d) 에 *윈도우 스텝 비율 (col_window_step_rate, s)* (초모수) 을 곱해 정한다.

$$ w_s = \lceil e_d \times s \rceil ; s \in \mathbb R, 0 \lt s \leq 1 $$

* 수집 윈도우는 스텝 단위로 슬라이딩하다가 종료일이 학습 데이터 종료일보다 커질 때 끝난다.

#### 슈도 코드

학습 데이터를 모으는 과정의 슈도 코드는 아래와 같다:

```
학습 데이터 시작일과 종료일에서 학습 데이터 (L) 초기화
학습 데이터 내 모든 유저에 대해
  총 접속일이 유효 접속일 수 (e_p) 에 미치지 못하면
    다음 유저로
  첫 접속일을 수집 윈도우 시작일로
  수집 윈도우에 대해
    수집 윈도우 종료일 (w_e) 를 구한다.
    수집 윈도우 종료일이 학습 데이터 종료일보다 크면
      다음 유저로
    유효 데이터 일 수 (e_d) 로 군집 결정 후, 윈도우 내 피처 데이터 (X) 를 군집 학습 데이터 (o) 에 넣음
    이탈 판정일 수 동안 접속일로 이탈 여부 라벨링 (y) 후 군집 학습 데이터에 넣음
    이탈했으면
      다음 유저로
    수집 윈도우 스텝으로 윈도우 진행
```

#### 학습 데이터 수집 도해

아래는 군집 6 에서 군집 3 으로 변한 후 이탈한 유저의 예이다.

* 공통 변수
  * 이탈 접속률 r_c = 4
  * 윈도우 스텝 비율 s = 0.3
  * 유효 접속일 수 e_p = 6

* 군집 6
  * 유효 데이터 일 수 e_d^6 = 7
  * 이탈 판정일 수 c_d^6 = 5
  * 윈도우 크기 w_w^6 = o_d^6 = e_d^6 + c_d^6 = 12
  * 윈도우 스텝 w_s^6 = 4

* 군집 3
  * 유효 데이터 일 수 e_d^3 = 12
  * 이탈 판정일 수 c_d^3 = 10
  * 윈도우 크기 w_w^3 = o_d^3 = e_d^3 + c_d^3 = 22
  * 윈도우 스텝 w_s^3 = 7

![수집 과정](/assets/2020-02-25-15-51-50.png)

### 초모수의 선택

여기서는 온라인 및 모바일 게임에서 단위 기간을 일주일로 한다고 할 때 다음과 같이 초모수들을 선택한다:

* 유효 접속일 수 (e_p)
  * 4 ~ 10 범위에서 예측 점수가 높은 것을 HPO로 선택

* 단위 기간 한계 접속일 수 (k^mar) = 3
  * 일주일에 세 번 오는 유저까지를 대상. 너무 가끔씩 접속하는 유저는 예측의 효용성이 작을 수 있다.

* 이탈 결석률 (r_c)
  * 학습 데이터에서 이탈 판정 후 다시 접속하는 비율을 에러율로 정하고
  * 3~10 범위에서 에러율이 작은 것을 HPO로 선택한다.

* 학습 데이터 일 수 (L_d)
  * 60 일로 한다.

* 윈도우 스텝 비율 (s)
  * 0.3 으로 한다.

> 어떤 서비스에서 어떤 척도를 사용하는지에 따라 다양한 초모수가 이용될 수 있겠다.

### 학습 진행

군집별 학습 데이터 (o^k) 에서 각각의 예측 모델을 (m^k) 를 학습한다.

* 모델 집합 (M) 내 각 군집에 대해 각각의 군집 학습 데이터 (group_learn_data, o^k) 로 구성

$$M = \{ m^k \vert k \in \mathbb Z, k^{mar} \leq k \leq U\}$$

* 예로, U = 7 이고 k^mar = 3 인 경우 모델 집합은 다음과 같다:
o
$$ M = \{ m^3, m^4, m^5, m^6, m^7 \}$$

#### 척도의 선택

> 실제 예측 모델이 목표로 해야할 것은 오차를 최소화하는 것이 아니라 모델 적용을 통해 기대되는 이익을 최대화 하는 것
>
> [실전 이탈 예측 모델링을 위한 세 가지 고려 사항](https://brunch.co.kr/@gimmesilver/53) 에서

흔히 사용되는 Accuracy, Recall, F1-Score 등의 척도의 선택도 *이익을 최대화* 하기 위한 방향으로 하는 것이 맞을 것이다.

예를 들어 제한된 프로모션 비용에서 이익의 최대화 하기 위해서 VIP 대상 이탈 예측을 선택할 수 있다. 이들은 결제를 유발할 수 있는 진성 유저들이기에 오탐을 두려워하지 말고 미탐이 적은 방향으로 학습 척도를 선택할 수 있겠다.

#### 학습 진행

학습 과정의 슈도 코드는 아래와 같다:

```
각 군집 (g^k) 에 대해:
  군집 모델 (m^k) 초기화
  군집별 학습 데이터 (o^k) 에 대해:
    피처 데이터 (X) 및 라벨 (y) 을 이용해 대해 척도 기준으로 학습
```

### 예측 데이터

학습된 모델로 실제 예측을 실시한다. 이때 예측을 위한 데이터가 필요하다.

*예측 데이터 (pred_data, P)* 는 기간 내 피처 데이터 (X) 로 구성되며, 유저의 이탈 여부를 예측하는데 사용된다. 학습 데이터와 겹치지 않도록 한다.

#### 용어와 개념

* *예측 데이터 일 수 (pred_data_days, P_d)* : 유저별 이탈 예측에 필요한 데이터의 일 수. 학습된 군집 모델 중 적절한 것을 선택할 수 있도록 유효 데이터 일 수 (e_d)와 같게 한다.

$$P_d = e_d$$

* *예측 데이터 종료일 (pred_data_end, P_e)* : 예측 데이터의 마지막 날자. 대개 예측일 (t) 전날이다.

* *예측 데이터 시작일 (pred_data_begin, P_b)* : 예측 데이터의 시작 날자. 예측 데이터 종료일에서 예측 데이터 일 수를 뺀 것

$$P_b = P_e - P_d$$

* 예측 데이터 내 결석률이 이탈 결석률 이상인 유저는 기이탈로 판단해 예측 대상에서 제외한다.

참고로, 학습 및 예측 데이터 기간과 예측일에는 다음과 같은 관계가 있다:

$$ L_{b} \lt L_{e} \lt P_{b} \lt P_{e} \lt t$$

#### 슈도 코드

예측 데이터를 모으는 과정의 슈도 코드는 아래와 같다:

```
예측 데이터 시작일과 종료일에서 예측 데이터 (P) 초기화
예측 데이터 내 모든 유저에 대해
  총 접속일이 유효 접속일 수 (e_p) 에 미치지 못하면
    다음 유저로
  결석률 (a) 이 이탈 결석률 (r_c) 이상이면
    다음 유저로
  유저의 유효 데이터 일 수 (e_d) 로 유저의 군집 (g^k) 결정
  선택된 군집의 모델 (m^k) 로 이탈 여부 예측
```
