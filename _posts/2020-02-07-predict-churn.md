---
layout: post
title: 이탈 예측을 어떻게 할 것인가?
description:
date: 2020-02-07
tags: [idea, draft]
---

예전에 게임 유저 이탈 예측을 시도해 보았는데, 성과가 썩 좋지는 않았다. 이번에 아래의 사항을 고려하여 다시 시도해보려 한다.

## 개선할 것

### 유저 플레이 빈도 고려

저번에는 매일 플레이하는 유저나, 주말에만 플레이하는 유저나 같은 모델을 사용했는데, 이 부분이 개선이 필요할 것 같다.

일반적으로 초기에는 열성적으로 매일 플레이하던 유저도 점점 접속일 간격이 벌어지면서 결국 이탈하는 경향이 있다. 반면 매일 플레이하다 갑자기 이탈하는 유저도 존재하는데, 이런 경우들을 구분해서 모델을 만들고 싶은 것이다.

### 고도화된 피처 엔지니어링 및 HPO

저번에는 수작업된 피처들과 적당히 선택한 초모수로 훈련하였다. 최근에 [Featuretools](https://www.featuretools.com) 등의 자동 피처 합성기와 Dask 나 Ray 클러스터를 이용한 초모수 최적화(Hyper-parameter Optimization) 테크닉을 알게되어 활용해보려 한다. 얼마 안되는 피처에서 대충 설정한 초모수 보다는 좋은 결과를 기대한다.

## 플레이 빈도별 유저 군집화

* 유저를 한 주당 플레이한 날의 평균에 따라 다음과 같이 분류한다.
* 군집 분류:
  * Ga - 일 주일에 5~7 회 플레이하는 유저군
  * Gb - 일 주일에 3~4 회 플레이하는 유저군
  * Gc - 일 주일에 1~2 회 플레이하는 유저군

* 평균 일주일에 한 번 미만으로 플레이하는 유저는 학습 및 예측 대상으로 하지 않는다.
* 일반적으로 Ga 군의 유저는 이탈 확률이 낮고, Gc 군의 유저는 높을 것으로 추정되며 징후도 다를 것이기에 개별적으로 학습한다.
* 시간이 흐름에 따라 유저가 속한 군집이 바뀔 것이기에, 기간 별로 유저의 군집을 매번 분류해 사용한다.

### 유저 군집의 활용

* 유저 군집별로 학습 / 예측 데이터를 준비한다.
* 유저 군집별로 예측 모델을 학습한다.

## 용어와 개념

> **주의 :** 아래 용어와 변수는 따로 명시되지 않으면 각 *유저* 에 관한 것이다. *군집* 은 유저가 속한 군집을 말한다.

* *예측일 (target_day, t)* : 이탈을 예측하는 날자
* *기간 (term, T)* : 학습 및 예측의 입력으로 사용되는 데이터의 범위 (일 단위)
* *기간 일 수 (days, d) : 기간 내 날자의 수
* *접속일 (play)* : 플레이한 날
* *결석일 (absent)* : 플레이하지 않은 날
* *마지막 접속일 (last_play, l)* : 기간내 마지막 접속일
* *기간 접속일 (plays, p_d)* : 주어진 기간 일 수 동안 접속한 수
  * 10 일 동안 4번 접속한 경우 $p_{10} = 4$
* *주당 접속일 수 (week_plays, w)* : 주어진 기간 동안 접속일 수를 주당 비율로 계산한 것.
  * 예로, d = 14 일 동안 p = 2 번 접속한 경우 w = 1
  * 기간 내 주당 접속일로 유저가 속한 군집을 결정한다.

$$w = \frac {p_d} {d} \times 7$$

* *군집 (group, G)* : 유저가 속한 군집.
* *군집 결정 일 수 (group_decide_days, G_d)* : 유저 군집 결정에 필요한 일 수
  * 이후 설명할 최대 군집 접속 주기 (G_f_max) 이상이며, 적정 수준을 유지하도록 *군집 결정일 비 (h)* (초모수) 의 비율로 정한다.
  * 예로, G_f_max = 7 일때 h = 4 이면 G_d = 28

$$G_d = G_{f_{max}} \times h, \{ h \in \mathbb R : 1 \leq h \}$$

* 군집 접속 주기 (*group_play_freq, G_f*) : 군집에 속한 유저가 몇일마다 접속하는지의 값. 군집 결정 일 수 (G_d) 동안 접속일 수 (p_G_d) 로 나눈 값

$$G_f = \frac {G_d} {p_{G_d}} $$

* *최대 군집 접속 주기 (*max_group_play_freq*, G_f_max)* : 모든 군집의 접속 주기 중 가장 큰 값. 앞서 언급한 세 그룹중 Gc의 값이며, 일반적으로 7

* *접속 예정일 (due_play_day, e)* : 기간 내 유저의 마지막 첨석일 이후 예상되는 다음 접속일. 마지막 접속일 (l) 과 군집 접속 주기 (G_f) 로 계산.

$$e = l + G_f$$

* *결석률 (absent_rate, r)* : 유저의 접속 예정일 (e) 이후, 예측일 (t) 까지 결석일 수를 군집 접속 주기 주기에 대한 비율로 나타낸 것 (0 이상)
  * 예로, 접속 주기가 3일인 군집에 속한 유저가, 6일 동안 결석했다면, 결석율은 1

$$r = max \left( \frac {t - e} {f} - 1, 0 \right) $$

* *이탈 결석률 (churn_absent_rate, r_c)* : 유저의 결석률이 이 값보다 크거나 같으면 이탈로 판정 (초모수)

* *군집 이탈 판정일 수 (group_churn_decide_days, G_c)* : 그룹내 유저의 이탈 여부 판정에 필요한 최소 날자 수. 이탈 결석률 (r_c) 과 군집 접속 주기 (G_f) 에서 계산
  * 예로, 접속 주기가 2 일인 군집에서, 이탈 결석률 r_c = 3 으로 사용하면, 군집 이탈 판정에 필요한 날자는 6 이 된다.

$$G_c = r_c \times G_f$$

* *최대 군집 이탈 판정일 수 (max_group_churn_decide_days, G_c_max)* : 모든 군집의 이탈 판정일 수 중 가장 큰 값. 앞서 언급한 세 그룹중 Gc의 값.

## 피처 준비

이탈 예측을 위한 피처는 대상 서비스 별로 다양할 것이나, 여기서는 온라인/모바일 게임을 위한 피처를 가정하였다.

### 대상 테이블

아래와 같은 이벤트에 대한 정보 (테이블) 를 이용하여, 수작업 또는 합성 피처를 만들게 된다.

* 로그인 / 아웃
* 플레이 동작 - NPC 킬, 아이템 습득, 아이템 강화, 존 이동, 던전/퀘스트 수행, 레벨업 등
* 소셜 활동 - 길드 관련 활동, 유저간 거래, 상점 이용, 채팅 횟수
* 기타 계정 관련 - 결제 여부

### 수작업 피처들

전통적 또는 경험적으로 선택된 피처들을 말한다. 몇 가지 예로 들면:

* 플레이 시간
* 결석률
* 던전/퀘스트 수행 수
* 아이템 강화 성공/실패
* 결제 여부

### 합성된 피처들

경험적으로 미처 발견하지 못한 피처가 이탈 예측의 중요한 변수가 될 수도 있다. 이에 예전에 소개한 Featuretools 의 [심층 피처 합성](https://haje01.github.io/2019/12/27/deep-feature-synthesis.html) 방식을 이용하여 합성된 피처들도 이용한다.

### 피처 필터링

수작업에 합성된 것까지 포함하면 굉장히 많은 피처를 다루게 될 것이다. 본격적인 모델 학습 전에 피처 필터링을 위한 단계를 통해 피처 수를 줄이는 것이 좋겠다.

## 데이터 준비

앞서 말한 개념과 피처를 통해 학습 및 예측을 위한 데이터를 준비하게 된다. 중요한 것은 **모든 유저가 대상**은 아니라는 점이다. 게임 가입 후 적응하지 못하여 초기에 이탈했거나 비정기적으로 플레이하는 유저, 그리고 어뷰징 툴을 사용하는 유저의 경우는 대상으로 하지 않는 것이 기대 이익을 최대화하는 이탈 검출을 위해 바람직할 것이다.

### 학습 데이터

*학습 데이터 (learn_data, L)* 는 *유저별 일단위 피처 (features, X)* 와 *라벨 (label, y)* 로 구성되며, 여기에서 각 군집별 학습 데이터가 만들어 진다.

#### 용어와 개념

* *기간 학습 데이터 (learn_data, L_T 줄여서 L)* : 대상 기간 (T)에 대한 학습 데이터. 줄여서 학습 데이터로 부름
* *학습 데이터 일 수 (learn_data_days, L_d)* : 학습 데이터의 날자 수
  * 데이터는 많을 수록 좋으나, 최근 경향을 반영하지 못하는 *개념 표류 (Concept Drifting)* 를 피하기 위해 적절하게 L_d 설정 (초모수)
* *학습 데이터 시작일 (learn_data_begin, L_b)* : 학습 데이터의 시작 날자
* *학습 데이터 종료일 (learn_data_end, L_e)* : 학습 데이터의 마지막 날자. 이어 설명할 예측 데이터 시작일 (P_b) 보다 작아야 함

$$ L_e < P_b $$

* 학습 데이터의 시작일은 학습 데이터 종료일 (L_e) 과 학습 데이터 일 수 (L_d) 로 결정

$$L_b = L_e - L_d$$

#### 군집 학습 데이터

학습 데이터에서 *군집 학습 데이터 (group_learn_data, R)* 를 다음과 같이 준비:

* 각 군집 Ga, Gb, Gc에 대해 각각의 학습 데이터 Ra, Rb, Rc 를 만들게 됨
* 같은 유저도 접속 주기가 계속 달라 질 수 있기에, 이어 설명할 수집 윈도우에서 해당 유저의 접속 주기를 지속적으로 분류하고, 일정 오차 범위 기준으로 R1, R2, R3 에 배정한다.
* 예 1 : 학습 데이터 내 어떤 유저가 Ga -> Gb -> Gc 순으로 군집이 변하다 이탈
  * 이 유저의 Ga 시기 데이터를 Ra 에 배정하고 비이탈로 라벨링
  * 이 유저의 Gb 시기 데이터를 Rb 에 배정하고 비이탈로 라벨링
  * 이 유저의 Gc 시기 데이터를 Rc 에 배정하고 이탈로 라벨링
* 예 2 : 학습 데이터 내 어떤 유저가 Gb 군집에서 바로 이탈
  * 이 유저의 전체 데이터를 Rb 에 배정하고 이탈로 라벨링

데이터 양을 늘리기 위해 유저별로 일종의 슬라이딩 윈도우인 *수집 윈도우 (col_window, W)* 를 적용해 데이터를 수집한다.

* 수집 윈도우의 시작은 학습 데이터 내 유저의 최초 접속일 부터
* *수집 윈도우 크기 (col_window_width, W_w)* : 윈도우의 크기는 군집 결정 및 군집별 이탈 판정이 가능하도록 설정
  * 즉, 군집 결정 일 수 (G_d) 과 최대 군집 이탈 판정일 수 (G_c_max)의 합보다 커야한다.

$$W_w \geq G_d + G_{c_{max}} $$

* *수집 윈도우 스텝 (col_window_step, W_s)* : 이 윈도우의 진행 스텝
  * 중복을 허용하되, 적정 수준을 유지하도록 윈도우 크기에 대해 c (초모수)의 비율로 정한다.

$$ W_s = W_w \times c, \{c \in \mathbb R : 0 \lt c \leq 1 \}$$

학습 데이터 내 유저별 데이터를 이 윈도우로 순회하며,

* 윈도우 내 주당 접속일 수 (w) 를 구하고, 데이터를 적합한 군집 학습 데이터에 배정
  * 윈도우 내 주당 접속일이 1 미만인 유저 데이터는 제외
* 이탈 (*churn*) 여부로 라벨링 (y)
  * 윈도우 내 결석률이 $r_c$ 이상인 유저는 이탈

#### 슈도 코드

학습 데이터를 모으는 과정의 슈도 코드는 아래와 같다:

```
학습 데이터 시작일과 종료일에서 학습 데이터 (L) 초기화
슬라이딩 윈도우 (W) 의 크기 (W_w) 와 스텝 (W_s) 을 계산
슬라이딩 윈도우 (W)로 학습 데이터 (L) 순회:
  각 유저 (u) 에 대해:
    윈도우 내에서 군집 결정 일 수 (G_d) 이상 플레이 하지 않았으면:
      다음 유저로
    유저 군집 결정
    군집 학습 데이터에 윈도우 내 유저 데이터 배정 (이탈 판정일 범위 데이터도 포함?)
    유저 결석률 계산
    이탈 결석률 (G_c) 이상 여부로 라벨링
```

### 학습

#### 초모수의 선택
학습에 앞서 정해야할 초모수는 군집 결정일 비 (h), 이탈 결석률 (r_c) 이다. 각각 휴리스틱 또는 HPO 를 통해 선택한다.

#### 척도의 선택

[gimmesilver](https://brunch.co.kr/@gimmesilver) 님은 [실전 이탈 예측 모델링을 위한 세 가지 고려 사항](https://brunch.co.kr/@gimmesilver/53) 글에서 다음과 같이 말하였다:

> 실제 예측 모델이 목표로 해야할 것은 오차를 최소화하는 것이 아니라 모델 적용을 통해 기대되는 이익을 최대화 하는 것

흔히 사용되는 Accuracy, Recall, F1-Score 등의 척도의 선택도 *이억을 최대화* 하기 위한 방향으로 하는 것이 맞을 것이다.

예를 들어 제한된 프로모션 비용에서 이익의 최대화 하기 위해서 VIP 대상 이탈 예측을 선택할 수 있다. 이들은 결제를 유발할 수 있는 진성 유저들이기에 오탐을 두려워하지 말고, 대해 미탐이 적은 방향으로 학습 척도를 선택

#### 학습 진행

학습 과정의 슈도 코드는 아래와 같다:

```
각 군집에 대해:
  군집 모델 초기화
  군집별 학습 데이터 내 유저 데이터 미니 배치에 대해:
    피처 및 라벨로 군집 모델 학습
```

### 예측 데이터

*예측 데이터 (pred_data, P)* 는 유저별 일단위 피처 (X) 로만 구성되며, 유저의 이탈 여부를 예측하는데 사용된다. 학습 데이터와 겹치지 않도록 한다.
* 각 군집 Ga, Gb, Gc에 대해 각각의 예측 데이터 Pa, Pb, Pc 를 만들게 됨
* 예측 데이터 내에서 유저의 군집은 변하지 않는 것으로 가정

#### 용어와 개념

* *예측 데이터 일 수 (pred_data_days, P_d)* 는 예측에 필요한 데이터의 일 수
  * 학습된 군집 모델 중 적절한 것을 선택할 수 있도록 G_d 보다 커야한다.
  * 충분한 정보를 갖되 너무 오래된 데이터 사용을 지양하도록 오프셋 (o) 설정 (초모수)

$$P_d = G_d + o$$

* *예측 데이터 종료일 (pred_data_end, P_e)* : 예측 데이터의 마지막 날자. 대개 예측일 (t) 전날이다.

* *예측 데이터 시작일 (pred_data_begin, P_b)* : 예측 데이터의 시작 날자. 예측 데이터 종료일에서 예측 데이터 일 수를 뺀 것

$$P_b = P_e - P_d$$

* 결석률이 이탈 결석률 이상인 유저는 기이탈로 판단해 데이터에서 제외한다.

일반적으로 다음과 같은 관계가 성립한다:

$$ L_{begin} \lt L_{end} \lt P_{begin} \lt P_{end} \lt t$$

* 기준일 (*base_day, b*) 은 예측일부터 플레이 주기 (f) x 1.5 일 전
* 예측일 이전 $W_w$ 일 데이터에 대해
* 최소 접속일 이상 플레이한 유저들에 대해
* 예측 당일 데이터는 사용하지 않음

#### 슈도 코드

예측 데이터를 모으는 과정의 슈도 코드는 아래와 같다:

```
예측 데이터 시작일과 종료일에서 예측 데이터 (P) 초기화
각 유저 (u) 에 대해:
  군집 결정 일 수 (G_d) 이상 플레이 하지 않았으면:
    다음 유저로
  최종 접속일 (l), 접속 예정일 (e)를 계산
  결석률 (r) 을 계산
  결석률이 r_c 이상이면:
    기이탈로 판단해 제외
  군집 선택
  선택된 군집 예측 데이터에 유저 데이터 배정
```

### 예측

예측 과정의 슈도 코드는 아래와 같다:

```
각 군집에 대해:
  군집별 예측 데이터내 유저 데이터에 대해:
    피처에서 이탈 여부 예측
```
