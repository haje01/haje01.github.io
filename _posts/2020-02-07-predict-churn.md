---
layout: post
title: 이탈 예측을 어떻게 할 것인가?
description:
date: 2020-02-07
tags: [idea, draft]
---

예전에 게임 유저 이탈 예측을 시도해 보았는데, 성과가 썩 좋지는 않았다. 이번에 아래의 사항을 고려하여 다시 시도해보려 한다.

## 개선할 것

### 유저 플레이 빈도 고려

저번에는 매일 플레이하는 유저나, 주말에만 플레이하는 유저나 같은 모델을 사용했는데, 이 부분이 개선이 필요한 것 같다.

일반적으로 초기에는 열성적으로 매일 플레이하던 유저도 점점 접속일 간격이 벌어지면서 결국 이탈하는 경향이 있다. 반면 매일 플레이하다 갑자기 이탈하는 유저도 존재하는데, 이런 경우들을 구분해서 모델을 만들고 싶은 것이다.

### 피처 합성 및 HPO 활용

저번에는 수작업된 피처들과 적당히 휴리스틱으로 선택한 초모수로 훈련하였다. 최근에 [Featuretools](https://www.featuretools.com) 등의 자동 피처 합성기와 Dask 나 Ray 클러스터를 이용한 초모수 최적화(Hyper-parameter Optimization) 테크닉을 알게되어 활용해보려 한다. 얼마 안되는 피처에서 대충 설정한 초모수 보다는 좋은 결과를 기대한다.

## 플레이 빈도별 유저 군집화

* 유저를 단위 기간 (아래에서 설명) 당 플레이한 날의 평균에 따라 다음과 같이 분류한다. (단위 기간 U = 7 (일주일) 이고, 단위 기간 한계 접속일 수 k^mar = 1 인 경우)
* 군집 분류:
  * g^1 - 단위 기간당 접속일이 1 일인 유저군
  * g^2 - 단위 기간당 접속일이 2 일인 유저군
  * ...
  * g^7 - 단위 기간당 접속일이 7 일인 유저군

* 단위 기간 당 최소 접속일 수 미만, 즉 위의 경우 일주일에 한 번 미만으로 플레이하는 유저는 학습 및 예측 대상으로 하지 않는다.
* 일반적으로 g^7 군의 유저는 이탈 확률이 낮고, g^1 군의 유저는 높을 것으로 추정되며 징후도 다를 것이기에 각 군집을 별도로 학습한다.
* 시간이 경과됨에 따라 유저가 속한 군집도 바뀔 것이기에, 기간 별로 유저의 군집을 매번 분류해 사용한다.

### 유저 군집의 활용

* 유저 군집별로 학습 / 예측 데이터를 준비한다.
* 유저 군집별로 예측 모델을 학습한다.

## 용어와 개념

* *예측일 (target_day, t)* : 이탈을 예측하는 날자
* *기간 (term, T)* : 시작일 (begin, b) 부터 종료일 (end, e) 까지의 범위를 지칭. 종료일 (e) 는 포함하지 않는다.
* *단위 기간* (unit_term, U) : 주로 사용하는 기간의 크기. 보통 U = 7, 즉 일주일로 한다.
* *기간 일 수 (days, d)* : 기간 내 날자의 수
* *접속일 (play)* : 유저가 플레이한 날
* *결석일 (absent)* : 유저가 플레이하지 않은 날
* *속일 (last_play, l)* : 유저의 기간 내 마지막 접속일
* *결석일 수 (absents, a)* : 유저가 기간 동안 결석한 일 수
  * 기간 내 마지막 접속일에서 기간의 마지막 날까지 결석일을 센다.
  * 예로, 마지막 날 e = 2020-02-10 인 기간에서 5 일을 마지막 (l = 2020-02-15) 으로 이후 결석  하고 있다면, 결석일 수 a = 4 가 된다

$$a = e - l - 1$$

* *기간 접속일 수 (plays, p)* : 기간 내 유저가 접속한 일 수
  * 주어진 기간 동안 4번 접속한 경우 $p = 4$

* *단위 기간당 접속일 수 (unit_plays, k)* : 기간 내 유저의 접속일 수를 단위 기간으로 계산한 것.
  * 예로, 단위 기간이 일주일 U = 7 일때 유저가 기간일 수 d = 14 동안 접속일 p = 2 인 경우 k = 1
  * 이 값으로 유저가 속한 군집을 결정하게 된다.
  * 최대값은 U 와 같다.

$$k = \lceil \frac {p} {d} \rceil \times U$$

* *단위 기간 한계 접속일 수 (unit_margin_play, k^mar)* : 단위 기간당 접속일 수 (k) 의 한계값. 유저의 단위 기간당 접속일이 이 값 미만이면 제외한다. (초모수)

* *접속 주기 (play_freq, f)* : 유저가 몇 일마다 접속하는지의 값. 기간 일 수 (d) 와 그간의 접속일 수 (p) 로 계산

$$f = \lceil \frac {d} {p} \rceil = \lceil \frac {U} {k} \rceil $$

* *최대 접속 주기 (max_play_freq, f^max)* : 접속 주기의 최대값. 단위 기간 한계 접속일 수 (k^mar) 로 계산.

$$f^{max} = \frac {U} {k^{mar}}$$

<!-- * *최대 단위 기간당 접속일 수 (max_unit_plays, k^max)* : 단위 기간당 접속일 중 가장 큰 값. 최소 접속 주기의 역

$$k^{max} = \frac {7} {min(f)}$$ -->

* *군집 (group, g^k)* : 기간 동안 유저가 속하는  집합. 단위 기간당 접속일 수 (k) 로 결정된다.
  * 예로, g^3 군집은 단위 기간당 접속일이 3 일인 유저의 군집이다.

* *군집 집합 (group set, G)* : 전체 군집의 모임

$$ G = \{g^k \vert k \in \mathbb Z \land k^{mar} \leq k \leq U \}$$

 * 단위 기간 (U) 와 단위 기간 한계 접속일 수 (k^mar) 에 의해 군집 집합이 결정된다. 예로, U = 7 이고 k^mar = 3 인 경우 군집 집합은 다음과 같다:

$$ G = \{ g^3, g^4, g^5, g^6, g^7 \}$$

* *유효 접속일 수 (effect_plays, e_p)* : 기간 종료일 기준으로 몇 번째 최근 접속일 데이터까지를 사용할지를 나타냄 (초모수)
  * 예로 e_p = 4 라는 것은, 유저의 기간내 최근 4 접속일 까지의 데이터를 사용하겠다는 뜻이다.
  * 유저의 군집 결정, 학습 및 예측에 필요한 데이터 범위 결정에 사용된다.
  * 이 값이 클 수록 모델 성능이 향상될 수 있으나, 많은 데이터가 필요하고 개념 표류 (Concept Drifting) 가 발생할 수 있다.

* *유효 데이터 일 수 (effect_data_days, e_d)* : 유저의 유효 접속일 수에 해당하는 데이터 수집에 필요한 일 수. 접속 주기 (f) 와 유효 접속일 수 (e_p) 으로 계산
  * 예로, 접속 주기 f = 2 인 유저에 대해 유효 접속일 수 e_p = 4 인 데이터를 모으려면 e_d = 8 일치 데이터를 확보해야 한다.

$$e_d = f \times e_p$$

* *최대 유효 데이터 일 수 (max_effect_data_days, e_d^max)* : 모든 유저의 유효 접속일 수 중 가장 큰 값. 전체 대상 유저에 대한 유효 데이터를 확보하려할 때 사용.
  * 최대 접속 주기 (f^max) 와 유효 접속일 수 (e_p) 으로 계산한다.
  * 예를 들어 f^max = 7 과 e_p = 4 인 경우, e_d^max = 7 x 4 = 28 로, 28 일분 데이터를 확보해야 한다.

$$e_d^{max} = f^{max} \times {e_p}$$

* *접속 예정일 (due_play_day, q)* : 기간 내 유저의 마지막 참석일 이후 예상되는 다음 접속일. 마지막 접속일 (l) 과 접속 주기 (f) 로 계산.

$$q = l + f$$

* *결석률 (absent_rate, r)* : 유저의 접속 예정일 (q) 이후, 예측일 (t) 까지 결석일 수를 접속 주기에 대한 비율로 나타낸 것 (0 이상).
  * 다양한 접속 주기의 유저들의 결석 정도를 일관성있게 평가하기 위한 값이다.
  * 예로, 접속 주기 f = 3 일인 유저가, 6일 동안 결석했다면 (a = 6), 결석율 r = 2.0

$$r = max \left( \frac {a} {f}, 0 \right) $$

* *이탈 결석률 (churn_absent_rate, r_c)* : 유저의 결석률이 이 값보다 크거나 같으면 이탈로 판정. 너무 늦지 않고, 너무 민감하지도 않도록 설정 (초모수)
  * 예로, r_c = 2 이면 두 번의 접속 주기만큼 결석하면 이탈이라는 뜻

* *이탈 판정일 수 (churn_decide_days, c_d)* : 유저의 이탈 판정에 필요한 최소 날자 수. 이탈 결석률 (r_c) 과 접속 주기 (f) 에서 계산
  * 예로, 접속 주기 f = 2 일인 유저에 대해 이탈 결석률 r_c = 3 으로 하면, 이탈 판정에 필요한 날자는 6 일이 된다.

$$c_d = r_c \times f$$

* *최대 이탈 판정일 수 (max_churn_decide_days, c^max)* : 모든 이탈 판정일 수 중 가장 큰 값. 최대 접속 주기 (f^max) 와 이탈 결석률 (r_c) 로 계산

$$c^{max} = f^{max} \times r_c$$

## 피처

이탈 예측을 위한 피처는 대상 서비스 별로 다양할 것이나, 여기서는 온라인 및 모바일 게임을 위한 피처를 가정하였다.

유저의 행동 로그에서 이탈을 예측한다는 것은 시계열 예측으로 보아야 하겠다. 먼저 다음과 같은 유저별 피처를 일단위로 구성하고, 여기에서 시간 경과에 따른 경향을 피쳐화하겠다.

### 직접 피처들

직접 피처는 테이블이나 로그의 특정 필드에서 바로 구할 수 있는 피처를 말한다.

#### 계정 피처
* 플레이 시간
* 아이템 습득 수
* 아이템 거래 수
* 채팅 수
* 던전/퀘스트 수행 수
* 아이템 강화 성공/실패
* 결제 수

####

#### 캐릭터 피처
* 레벨 증가

### 합성된 피처들

수작업 미처에서 미처 발견하지 못한 피처가 이탈 예측의 중요한 변수가 될 수도 있다. 이에 예전에 소개한 Featuretools 의 [심층 피처 합성](https://haje01.github.io/2019/12/27/deep-feature-synthesis.html) 방식을 이용하여 합성된 피처들도 이용한다.

### 피처 필터링

수작업에 합성된 것까지 포함하면 굉장히 많은 피처를 다루게 될 것이다. 본격적인 모델 학습 전에 피처 필터링 단계를 통해 피처 수를 줄이는 것이 좋겠다.

## 데이터 준비

앞서 말한 개념과 피처를 통해 학습 및 예측을 위한 데이터를 준비하게 된다. 중요한 것은 *모든 유저가 대상은 아니라는 점* 이다. 게임 가입 후 적응하지 못하여 초기에 이탈했거나 비정기적으로 플레이하는 유저, 그리고 어뷰징 툴을 사용하는 등의 유저의 경우는 대상으로 하지 않는 것이 *기대 이익을 최대화하는 이탈 검출* 을 위해 바람직할 것이다.

### 학습 데이터

*학습 데이터 (learn_data, L)* 는 *유저별 일 단위 피처 (features, X)* 와 *라벨 (label, y)* 로 구성되며, 여기에서 각 군집별 학습 데이터가 만들어 진다.

#### 용어와 개념

* *학습 데이터 (learn_data, L_T 줄여서 L)* : 대상 기간 (T) 에 대한 학습 데이터. 줄여서 *학습 데이터* 로 부름.
* *학습 데이터 일 수 (learn_data_days, L_d)* : 기간 내 학습 데이터의 날자 수
  * 데이터는 많을 수록 좋으나, 개념 표류를 피하도록 적절한 L_d 설정 (초모수)
  * 적어도 이후 설명할 최소 학습 데이터 일 수 (L_d_min) 이상이어야 한다.

$$L_d \geq L_d^{min}$$

* *최소 학습 데이터 일 수 (min_learn_data_days, L_d^min)* : 학습 용 데이터는 군집 결정 및 이탈 판정이 가능해야하는데, 이를 위해 필요한 최소한의 데이터 날자 수.
  * 최대 유효 데이터 일 수 (e_d^max) 와 최대 이탈 판정일 수 (c^max) 의 합이다.
  * 예로, 최대 유효 데이터 일 수 e_d^max = 28 이고 최대 이탈 판정일 수 c^max = 14 이면 L_d^min 은 42 가 된다.

$$L_d^{min} = e_d^{max} + c^{max}$$

* *학습 데이터 시작일 (learn_data_begin, L_b)* : 학습 데이터의 시작 날자.
* *학습 데이터 종료일 (learn_data_end, L_e)* : 학습 데이터의 마지막 날자. 이어 설명할 예측 데이터 시작일 (P_b) 보다 작아야 함

$$ L_e < P_b $$

* 학습 데이터의 시작일은 학습 데이터 종료일 (L_e) 과 학습 데이터 일 수 (L_d) 로 결정

$$L_b = L_e - L_d$$

#### 군집 학습 데이터

앞에서 주간 접속일 수 (k) 로 유저의 군집을 배정하는 것을 살펴보았다. 이제 학습 데이터에서 *군집 학습 데이터 집합 (group_learn_data_set, O)* 을 다음과 같이 준비한다:

* 군집 집합 (G) 내 각 군집에 대해 각각의 군집 학습 데이터 (group_learn_data, o^k) 로 구성

$$O = \{ o^k \vert k \in \mathbb Z, k^{mar} \leq k \leq U\}$$

* 예로, U = 7 이고 k^mar = 3 인 경우 군집 학습 데이터 집합은 다음과 같다:

$$ O = \{ o^3, o^4, o^5, o^6, o^7 \}$$

* *군집 유효 데이터 일 수 (group_effect_data_days, e_d^k)* : 군집 유저의 유효 데이터 일 수 (e_d) 와 같다.

* *군집 이탈 판정일 수 (group_effect_data_days, c_d^k)* : 군집 유저의 이탈 판정일 수 (c_d) 와 같다.

* *군집 학습 데이터 일 수 (group_learn_data_days, o_d^k)* : 군집별 학습 데이터는 군집의 결정 및 이탈 판정이 가능한 크기여야 하는데, 이를 위한 최소한의 데이터 날자 수.
  * 군집 유효 데이터 일 수 (e_d^k) 와 군집 이탈 판정일 수 (c_d^k) 의 합이다.
  * 예로, 유효 데이터 일 수 e_d = 28 이고 이탈 판정일 수 c^d = 14 이면 o_d^k 는 42 가 된다.

$$o_d^k = e_d^k + c_d^k$$

* 같은 유저도 경과에 따라 접속 주기가 계속 달라 질 수 있기에, 이어 설명할 수집 윈도우를 학습 데이터 (L) 에 적용해 해당 유저의 접속 주기를 순차적으로 분류하고, 군집에 배정한다.
* 예 : 학습 데이터 내 어떤 유저가 수집 윈도우 별로 g^5 -> g^3 -> g^1 순으로 군집이 변하다 이탈
  * 이 유저의 g^5 시기 데이터를 o^5 에 배정하고 비이탈로 라벨링
  * 이 유저의 g^3 시기 데이터를 o^3 에 배정하고 비이탈로 라벨링
  * 이 유저의 g^1 시기 데이터를 o^1 에 배정하고 이탈로 라벨링

* *수집 윈도우 (col_window, w^k)* : 군집별 학습 데이터를 순회하며 데이터를 수집하는 윈도우.
  * 데이터 양을 늘리고 군집에 맞는 데이터 수집을 위해 이용
  * 군집별로 하나씩 할당
* *수집 윈도우 집합 (col_window_set, W)* : 학습 데이터 내 모든 군집별 수집 윈도우의 집합

$$W = \{ w^k \vert k \in \mathbb Z, k^{mar} \leq k \leq U \}$$

* 예로, U = 7 이고 k^mar = 3 인 수집 윈도우 집합은 다음과 같다:

$$W = \{ w^3, w^4, w^5, w^6, w^7 \}$$

* *수집 윈도우 시작일 (col_window_begin, w_b^k)* : 특정 윈도우의 시작일. 슬라이딩되면서 윈도우 스텝만큼 증가.
* *수집 윈도우 크기 (col_window_width, w_w^k)* : 윈도우 크기는 해당 군집의 학습 데이터 일 수 (o_d^k) 와 같게 한다.

$$w_w^k = o_d^k$$

* *수집 윈도우 종료일 (col_window_end, w_e^k)* : 특정 윈도우의 종료일. 시작일과 크기에서 계산

$$w_e^k = w_b^k + w_w^k$$

* *수집 윈도우 스텝 (col_window_step, w_s^k)* : 윈도우의 진행 스텝.
  * 중복을 허용하되, 적정 수준을 유지하도록 윈도우 크기에 대해 s (초모수) 의 비율로 정한다.

$$ w_s^k = \lceil w_w^k \times s \rceil ; s \in \mathbb R, 0 \lt s \leq 1 $$

* *수집 윈도우 종료일 (col_window_end, w_e^k)* : 윈도우 기간의 종료일
  * 수집 윈도우 시작일과 스텝으로 계산
  * 학습 데이터 종료일 (L_e) 이하여야 한다.

$$w_e^k = w_b^k + w_s^k ; w_e^k \leq L_e$$

* 수집 윈도우 내 데이터는 유효 데이터 일 수 (e_d^g) 와 이탈 판정일 수 (c_d^g) 로 나뉜다.
  * 유효 데이터 일 수의 데이터는 학습에 사용되고, 최대 이탈 판정일 수의 데이터는 라벨링에만 사용된다.

* 수집 윈도우의 진행은 스텝 단위로 하다가 종료일이 학습 데이터 커질 때 마친다.

#### 슈도 코드

학습 데이터를 모으는 과정의 슈도 코드는 아래와 같다:

```
학습 데이터 시작일과 종료일에서 학습 데이터 (L) 초기화
학습 데이터 내 모든 유저에 대해
  총 접속일이 유효 접속일 수 (e_p) 에 미치지 못하면
    다음 유저로
  첫 접속일부터 유효 접속일 수 기간 데이터로 군집 (g^k) 및 수집 윈도우 (w^k) 를 결정
  수집 윈도우에 대해
    기간 피처 데이터 (X) 를 군집 학습 데이터 (o) 에 넣음
    이탈 여부 라벨링 (y) 후 군집 학습 데이터에 넣음
    이탈했으면
      다음 유저로
    수집 윈도우 (w^k) 진행
```

### 초모수의 선택

여기서는 온라인 및 모바일 게임에서 단위 기간을 일주일로 한다고 할 때 다음과 같이 초모수들을 선택한다:

* 유효 접속일 수 (e_p) = 7
  * 최근 7 접속일 데이터를 보도록 하겠다.

* 단위 기간 한계 접속일 수 (k^mar) = 3
  * 3 일에 한 번은 오는 유저까지를 대상. 너무 가끔씩 접속하는 유저는 예측의 효용성이 작을 수 있다.
  * k^mar = 1 로 하면 군집이 없는 단순한 구성을 할 수 있다.

* 이탈 결석률 (r_c) = 5
  * 5 주기 이상 접속하지 않는 유저는 이탈

* 학습 데이터 일 수 (L_d) = 30
  * 한 달로 한다. 3일에 한 번 오는 유저의 경우 10 접속일 데이터를 볼 수 있겠다.

* 수집 윈도우 스텝 (w_s^k) = 7
  * 일주일 스텝으로 수집 윈도우를 진행

> 어떤 서비스에서 어떤 척도를 사용하는지에 따라 다양한 초모수가 이용될 수 있겠다.

### 학습 진행

군집별 학습 데이터 (o^k) 에서 각각의 예측 모델을 (m^k) 를 학습한다.

* 모델 집합 (M) 내 각 군집에 대해 각각의 군집 학습 데이터 (group_learn_data, o^k) 로 구성

$$M = \{ m^k \vert k \in \mathbb Z, k^{mar} \leq k \leq U\}$$

* 예로, U = 7 이고 k^mar = 3 인 경우 모델 집합은 다음과 같다:

$$ M = \{ m^3, m^4, m^5, m^6, m^7 \}$$

#### 척도의 선택

[gimmesilver](https://brunch.co.kr/@gimmesilver) 님은 [실전 이탈 예측 모델링을 위한 세 가지 고려 사항](https://brunch.co.kr/@gimmesilver/53) 글에서 다음과 같이 말하였다:

> 실제 예측 모델이 목표로 해야할 것은 오차를 최소화하는 것이 아니라 모델 적용을 통해 기대되는 이익을 최대화 하는 것

흔히 사용되는 Accuracy, Recall, F1-Score 등의 척도의 선택도 *이익을 최대화* 하기 위한 방향으로 하는 것이 맞을 것이다.

예를 들어 제한된 프로모션 비용에서 이익의 최대화 하기 위해서 VIP 대상 이탈 예측을 선택할 수 있다. 이들은 결제를 유발할 수 있는 진성 유저들이기에 오탐을 두려워하지 말고 미탐이 적은 방향으로 학습 척도를 선택할 수 있겠다.

#### 학습 진행

학습 과정의 슈도 코드는 아래와 같다:

```
각 군집 (g^k) 에 대해:
  군집 모델 (m^k) 초기화
  군집별 학습 데이터 (o^k) 에 대해:
    피처 데이터 (X) 및 라벨 (y) 을 이용해 대해 척도 기준으로 학습
```

### 예측 데이터

학습된 모델로 실제 예측을 실시한다. 이때 예측을 위한 데이터가 필요하다.

*예측 데이터 (pred_data, P)* 는 기간 내 피처 데이터 (X) 로 구성되며, 유저의 이탈 여부를 예측하는데 사용된다. 학습 데이터와 겹치지 않도록 한다.

#### 용어와 개념

* *예측 데이터 일 수 (pred_data_days, P_d)* : 유저별 이탈 예측에 필요한 데이터의 일 수. 학습된 군집 모델 중 적절한 것을 선택할 수 있도록 유효 데이터 일 수 (e_d)와 같게 한다.

$$P_d = e_d$$

* *예측 데이터 종료일 (pred_data_end, P_e)* : 예측 데이터의 마지막 날자. 대개 예측일 (t) 전날이다.

* *예측 데이터 시작일 (pred_data_begin, P_b)* : 예측 데이터의 시작 날자. 예측 데이터 종료일에서 예측 데이터 일 수를 뺀 것

$$P_b = P_e - P_d$$

* 예측 데이터 내 결석률이 이탈 결석률 이상인 유저는 기이탈로 판단해 예측 대상에서 제외한다.

참고로, 학습 및 예측 데이터 기간과 예측일에는 다음과 같은 관계가 있다:

$$ L_{b} \lt L_{e} \lt P_{b} \lt P_{e} \lt t$$

#### 슈도 코드

예측 데이터를 모으는 과정의 슈도 코드는 아래와 같다:

```
예측 데이터 시작일과 종료일에서 예측 데이터 (P) 초기화
예측 데이터 내 모든 유효한 유저에 대해
  총 접속일이 유효 접속일 수 (e_p) 에 미치지 못하면
    다음 유저로
  결석률 (a) 이 이탈 결석률 (r_c) 이상이면
    다음 유저로
  유저의 단위 기간당 접속일 수 (k) 로 유저의 군집 (g^k) 결정
  선택된 군집의 모델 (m^k) 로 이탈 여부 예측
```
