---
layout: post
title: 이탈 예측을 어떻게 할 것인가?
description:
date: 2020-02-07
tags: [idea, draft]
---

예전에 게임 유저 이탈 예측을 시도해 보았는데, 성과가 썩 좋지는 않았다. 이번에 아래의 사항을 고려하여 다시 시도해보려 한다.

## 개선할 것

### 유저 플레이 빈도 고려

저번에는 매일 플레이하는 유저나, 주말에만 플레이하는 유저나 같은 모델을 사용했는데, 이 부분이 개선이 필요한 것 같다.

일반적으로 초기에는 열성적으로 매일 플레이하던 유저도 점점 접속일 간격이 벌어지면서 결국 이탈하는 경향이 있다. 반면 매일 플레이하다 갑자기 이탈하는 유저도 존재하는데, 이런 경우들을 구분해서 모델을 만들고 싶은 것이다.

### 고도화된 피처 엔지니어링 및 HPO

저번에는 수작업된 피처들과 적당히 휴리스틱으로 선택한 초모수로 훈련하였다. 최근에 [Featuretools](https://www.featuretools.com) 등의 자동 피처 합성기와 Dask 나 Ray 클러스터를 이용한 초모수 최적화(Hyper-parameter Optimization) 테크닉을 알게되어 활용해보려 한다. 얼마 안되는 피처에서 대충 설정한 초모수 보다는 좋은 결과를 기대한다.

## 플레이 빈도별 유저 군집화

* 유저를 한 주당 플레이한 날의 평균에 따라 다음과 같이 분류한다.
* 군집 분류:
  * g^1 - 주당 접속일이 1 일인 유저군
  * g^2 - 주당 접속일이 2 일인 유저군
  * ...
  * g^7 - 주당 접속일이 7 일인 유저군

* 평균 일주일에 한 번 미만으로 플레이하는 유저는 학습 및 예측 대상으로 하지 않는다.
* 일반적으로 g^7 군의 유저는 이탈 확률이 낮고, g^1 군의 유저는 높을 것으로 추정되며 징후도 다를 것이기에 각 군집을 별도로 학습한다.
* 유저의 플레이 시간이 누적됨에 따라 속한 군집도 바뀔 것이기에, 기간 별로 유저의 군집을 매번 분류해 사용한다.

### 유저 군집의 처리

* 유저 군집별로 학습 / 예측 데이터를 준비한다.
* 유저 군집별로 예측 모델을 학습한다.

## 용어와 개념

* *예측일 (target_day, t)* : 이탈을 예측하는 날자
* *기간 (term, T_b_e 간략히 T)* : 시작일 (begin, b) 부터 종료일 (end, e) 까지의 범위를 지칭. 종료일 (e) 는 제외한다.
* *기간 일 수 (days, d)* : 기간 내 날자의 수
* *접속일 (play)* : 유저가 플레이한 날
* *결석일 (absent)* : 유저가 플레이하지 않은 날
* *마지막 접속일 (last_play, l)* : 유저의 기간 내 마지막 접속일
* *결석일 수 (absents, a)* : 유저가 기간 동안 결석한 일 수
  * 기간 내 마지막 접속일에서 기간의 마지막 날까지 결석일을 센다.
  * 예로, 마지막 날 (미포함) e = 10 인 기간에서 5 일 이후 결석하고 있다 (l = 5) 면, 결석일 수는 a = 6 이 된다

$$a = e - l - 1$$

* *기간 접속일 수 (plays, p_d)* : 기간 내 유저가 접속한 일 수
  * 10 일 동안 4번 접속한 경우 $p_{10} = 4$
* *주당 접속일 수 (week_plays, k)* : 기간 내 유저의 접속일 수를 주 단위로 계산한 것.
  * 예로, 유저가 d = 14 일 동안 p = 2 번 접속한 경우 w = 1
  * 기간 내 주당 접속일로 유저가 속한 군집을 결정한다.

$$w = \lceil \frac {p_d} {d} \rceil \times 7$$

* *접속 주기 (play_freq, f)* : 유저가 몇 일마다 접속하는지의 값. 기간 일 수 (d) 와 그 동안의 접속일 수 (p_d) 로 계산

$$f = \lceil \frac {d} {p_d} \rceil = \lceil \frac {7} {w} \rceil $$

* *최대 접속 주기 (max_play_freq, f_max)* : 접속 주기의 최대값. 접속 주기가 이 값 이상인 유저는 제외한다. (상수, f_max = 7)

* *군집 (group, g^k)* : 기간 동안 유저가 속하는  집합. 주당 접속일 수 (k)로 결정한다.
  * 예로, g^3 군집은 주당 접속일이 3 일인 유저의 그룹이다.
* *최대 군집 수 (group_max, m)* : 다룰 군집의 수
* *군집 집합 (group set, G_m)* : 전체 군집의 모임

$$ G = \{g^x \vert x \in \mathbb Z \land 1 \leq x \leq w_{max} \}$$

 * 최대 접속 주기 f_max = 7 인 군집 셋은 다음과 같다:

$$ G = \{ g^1, g^2, g^3, g^4, g^5, g^6, g^7 \}$$

* *유효 접속일 수 (effect_plays, e_p)* : 기간 종료일 기준으로 몇 번째 최근 접속일 데이터까지를 사용할지를 나타냄 (초모수)
  * 예로 q = 4 이라는 것은, 유저의 기간내 최근 4 개 접속일의 데이터를 사용하겠다는 뜻이다.
  * 유저의 군집 결정, 학습 및 예측에 필요한 데이터 범위 결정에 사용된다.
  * 이 값이 클 수록 성능이 향상될 수 있으나, 동시에 많은 데이터가 필요하고 개념 표류 (Concept Drifting) 가 발생할 수 있다.

* *유효 데이터 일 수 (effect_data_days, e_d)* : 모든 대상 유저의 유효 접속일 수에 해당하는 데이터 수집에 필요한 일 수. 최대 접속 주기 (f_max) 와 유효 접속일 수 (e_p) 으로 계산.
  * 예를 들어 f_max = 7 과 e_p = 4 를 이용하면 e_d = 7 x 4 = 28 로, 28 일분 데이터의 검색이 필요하다.
  * 그러나, 그 기간동안 실제 유저의 접속일은 4일 정도일 것이기에, 그 정도의 데이터만 활용할 수 있다.

$$e_d = f_{max} \times {e_p}$$

* 위의 예에서 알 수 있듯, 실제 활용하는 데이터에 비해 다루어야할 데이터가 너무 많아지기에, 적절한 유효 접속일 수 (e_p) 및 최대 접속 주기 (f_max) 의 선정이 필요하다.

* *접속 예정일 (due_play_day, q)* : 기간 내 유저의 마지막 참석일 이후 예상되는 다음 접속일. 마지막 접속일 (l) 과 접속 주기 (f) 로 계산.

$$e = l + f$$

* *결석률 (absent_rate, r)* : 유저의 접속 예정일 (q) 이후, 예측일 (t) 까지 결석일 수를 접속 주기에 대한 비율로 나타낸 것 (0 이상).
  * 다양한 접속 주기의 유저들의 결석 정도를 일관성있게 평가하기 위한 값이다.
  * 예로, 접속 주기 f = 3 일인 군집에 속한 유저가, 6일 동안 결석했다면 (a = 6), 결석율 r = 1.0

$$r = max \left( \frac {a} {f} - 1, 0 \right) $$

* *이탈 결석률 (churn_absent_rate, r_c)* : 유저의 결석률이 이 값보다 크거나 같으면 이탈로 판정 (초모수).
  * 예로, r_c = 2 이면 두 번의 접속 주기만큼 결석하면 이탈이라는 뜻

* *이탈 판정일 수 (churn_decide_days, c_d)* : 특정 유저의 이탈 판정에 필요한 최소 날자 수. 이탈 결석률 (r_c) 과 접속 주기 (f) 에서 계산
  * 예로, 접속 주기 f = 2 일인 유저에 대해 이탈 결석률 r_c = 3 으로 하면, 이탈 판정에 필요한 날자는 6 일이 된다.

$$c_d = r_c \times f$$

* *최대 이탈 판정일 수 (max_churn_decide_days, c_max)* : 모든 이탈 판정일 수 중 가장 큰 값. 최대 접속 주기 (f_max) 와 이탈 결석률 (r_c) 로 계산

$$c_{max} = f_{max} \times r_c$$

## 피처 준비

이탈 예측을 위한 피처는 대상 서비스 별로 다양할 것이나, 여기서는 온라인 및 모바일 게임을 위한 피처를 가정하였다.

### 대상 테이블

예로, 아래와 같은 이벤트에 대한 정보 (테이블) 를 이용하여, 수작업 또는 합성 피처를 만들게 된다.

* 로그인 / 아웃
* 플레이 동작 - NPC 킬, 아이템 습득, 아이템 강화, 존 이동, 던전/퀘스트 수행, 레벨업 등
* 소셜 활동 - 길드 관련 활동, 유저간 거래, 상점 이용, 채팅 횟수
* 기타 계정 관련 - 결제 여부

### 수작업 피처들

경험적 또는 탐색적 데이터 분석 등의 피처 공학 (Feature Engineering) 으로 만들어진 피처들을 말한다. 몇 가지 예로 들면:

* 플레이 시간
* 결석률
* 던전/퀘스트 수행 수
* 아이템 강화 성공/실패
* 결제 여부

### 합성된 피처들

수작업 미처에서 미처 발견하지 못한 피처가 이탈 예측의 중요한 변수가 될 수도 있다. 이에 예전에 소개한 Featuretools 의 [심층 피처 합성](https://haje01.github.io/2019/12/27/deep-feature-synthesis.html) 방식을 이용하여 합성된 피처들도 이용한다.

### 피처 필터링

수작업에 합성된 것까지 포함하면 굉장히 많은 피처를 다루게 될 것이다. 본격적인 모델 학습 전에 피처 필터링 단계를 통해 피처 수를 줄이는 것이 좋겠다.

## 데이터 준비

앞서 말한 개념과 피처를 통해 학습 및 예측을 위한 데이터를 준비하게 된다. 중요한 것은 *모든 유저가 대상은 아니라는 점* 이다. 게임 가입 후 적응하지 못하여 초기에 이탈했거나 비정기적으로 플레이하는 유저, 그리고 어뷰징 툴을 사용하는 등의 유저의 경우는 대상으로 하지 않는 것이 *기대 이익을 최대화하는 이탈 검출* 을 위해 바람직할 것이다.

### 학습 데이터

*학습 데이터 (learn_data, L)* 는 *유저별 일 단위 피처 (features, X)* 와 *라벨 (label, y)* 로 구성되며, 여기에서 각 군집별 학습 데이터가 만들어 진다.

#### 용어와 개념

* *학습 데이터 (learn_data, L_T 줄여서 L)* : 대상 기간 (T) 에 대한 학습 데이터. 줄여서 *학습 데이터* 로 부름.
* *학습 데이터 일 수 (learn_data_days, L_d)* : 기간 내 학습 데이터의 날자 수
  * 데이터는 많을 수록 좋으나, 개념 표류를 피하도록 적절한 L_d 설정 (초모수)

* *최소 학습 데이터 일 수 (min_learn_data_days, L_d_max)* : 학습 용 데이터는 군집 결정 및 이탈 판정이 가능해야하는데, 이를 위한 최소한의 데이터 날자 수.
  * 유효 데이터 일 수 (e_d) 와 최대 이탈 판정일 수 (c_max) 의 합이다.
  * 예로, 유효 데이터 일 수 e_d = 28 이고 최대 이탈 판정일 수 c_max = 14 이면 L_d_max 는 42 가 된다.

$$L_{d_{max}} = e_d + c_{max}$$

* 학습 데이터 일 수 (e_d) 는 적어도 최소 학습 데이터 일 수 (L_d_max) 이상 이어야 한다.

$$L_d \geq L_{d_{max}}$$

* *학습 데이터 시작일 (learn_data_begin, L_b)* : 학습 데이터의 시작 날자.
* *학습 데이터 종료일 (learn_data_end, L_e)* : 학습 데이터의 마지막 날자. 이어 설명할 예측 데이터 시작일 (P_b) 보다 작아야 함

$$ L_e < P_b $$

* 학습 데이터의 시작일은 학습 데이터 종료일 (L_e) 과 학습 데이터 일 수 (L_d) 로 결정

$$L_b = L_e - L_d$$

#### 군집 학습 데이터

앞에서 주간 접속일 수 (k) 로 유저의 군집을 배정하는 것을 살펴보았다. 이제 학습 데이터에서 *군집 학습 데이터 셋 (group_learn_data, O)* 을 다음과 같이 준비한다:

* 군집 집합 (G) 내 각 군집에 대해 각각의 학습 데이터 o^1, o^2, ..., o^7 을 만들게 됨

$$O = \{ o^1, o^2, o^3, o^4, o^5, o^6, o^7 \}$$

* 같은 유저도 경과에 따라 접속 주기가 계속 달라 질 수 있기에, 이어 설명할 수집 윈도우를 학습 데이터 (L) 에 적용해 해당 유저의 접속 주기를 순차적으로 분류하고, 군집에 배정한다.
* 예 : 학습 데이터 내 어떤 유저가 수집 윈도우 별로 g^5 -> g^3 -> g^1 순으로 군집이 변하다 이탈
  * 이 유저의 g^5 시기 데이터를 o^5 에 배정하고 비이탈로 라벨링
  * 이 유저의 g^3 시기 데이터를 o^3 에 배정하고 비이탈로 라벨링
  * 이 유저의 g^1 시기 데이터를 o^1 에 배정하고 이탈로 라벨링

* *수집 윈도우 (col_window, w)* : 학습 데이터를 순차적으로 순회하며 데이터를 수집하는 윈도우. 데이터 양을 늘리고 시기별 분류에 맞는 데이터 수집을 위해 이용
* *수집 윈도우 집합 (col_window_set, W)* : 학습 데이터 내 모든 개별 수집 윈도우의 집합

$$W = \{ w^1, w^2, ..., w^n \}$$

* *수집 윈도우 시작일 (col_window_begin, w_b)*: : 윈도우 기간의 시작일
* *수집 윈도우 크기 (col_window_width, w_w)* : 윈도우 크기는 군집 결정 및 이탈 판정이 가능하도록 최소 학습 데이터 일 수 (L_d_max) 와 같게 한다.

$$w_w = L_{d_{max}}$$

* *수집 윈도우 스텝 (col_window_step, w_s)* : 윈도우의 진행 스텝.
  * 중복을 허용하되, 적정 수준을 유지하도록 윈도우 크기에 대해 c (초모수)의 비율로 정한다.

$$ w_s = \lceil w_w \times c \rceil, \{c \in \mathbb R : 0 \lt c \leq 1 \}$$

* n 번째 윈도우의 시작일은 아래와 같다:

$$w^n_b = L_b + w_s * (n - 1)$$

* *수집 윈도우 종료일 (col_window_end, w_e)*: 윈도우 기간의 종료일
  * 수집 윈도우 시작일과 스텝으로 계산
  * 학습 데이터 종료일 (L_e) 이하여야 한다.

$$w_e = w_b + w_s, w_e \leq L_e$$

* 수집 윈도우 내 데이터는 크게 유효 데이터 일 수 (e_d) 와 최대 이탈 판정일 수 (c_max) 로 나뉜다.
  * 유효 데이터 일 수의 데이터는 학습에 사용되고, 최대 이탈 판정일 수의 데이터는 라벨링에만 사용된다.

#### 슈도 코드

학습 데이터를 모으는 과정의 슈도 코드는 아래와 같다:

```
학습 데이터 시작일과 종료일에서 학습 데이터 (L) 초기화
슬라이딩 윈도우 (w) 의 크기 (w_w) 와 스텝 (w_s) 초기화
슬라이딩 윈도우 (w) 로 학습 데이터 (L) 순회
  윈도우 내 데이터의 각 유저 데이터에 대해
    유저의 기간 내 첫 접속일이 시작일보다 늦거나, 유효 접속일 수 (e_p) 이상 플레이하지 않았으면
      다음 유저로

    유저의 주당 접속일 수 (k) 로 유저의 군집 결정
    유효 데이터 일 수 (e_d) 이후 결석일 수 (a) 가 이탈 판정일 수 (c_d) 이상이면 결석으로 라벨링
    해당 군집의 학습 데이터 (o) 에 유저 데이터 (X) 와 라벨 (y) 추가 (이탈 판정에 사용한 데이터도 포함)
```

결과적으로 수집된 학습 데이터는, 군집에 관계없이 유저당 비슷한 일 수의 피처 데이터를 가지게 될 것이다.

### 학습 진행

#### 척도의 선택

[gimmesilver](https://brunch.co.kr/@gimmesilver) 님은 [실전 이탈 예측 모델링을 위한 세 가지 고려 사항](https://brunch.co.kr/@gimmesilver/53) 글에서 다음과 같이 말하였다:

> 실제 예측 모델이 목표로 해야할 것은 오차를 최소화하는 것이 아니라 모델 적용을 통해 기대되는 이익을 최대화 하는 것

흔히 사용되는 Accuracy, Recall, F1-Score 등의 척도의 선택도 *이억을 최대화* 하기 위한 방향으로 하는 것이 맞을 것이다.

예를 들어 제한된 프로모션 비용에서 이익의 최대화 하기 위해서 VIP 대상 이탈 예측을 선택할 수 있다. 이들은 결제를 유발할 수 있는 진성 유저들이기에 오탐을 두려워하지 말고 미탐이 적은 방향으로 학습 척도를 선택할 수 있겠다.

#### 학습 진행

학습 과정의 슈도 코드는 아래와 같다:

```
각 군집에 대해:
  군집 모델 초기화
  군집별 학습 데이터 미니 배치에 대해:
    피처 데이터 (X) 및 라벨 (y) 에 대해 척도 기준으로 군집 모델 학습
```

### 예측 데이터

*예측 데이터 (pred_data, P)* 는 기간 내 피처 데이터 (X) 로만 구성되며, 유저의 이탈 여부를 예측하는데 사용된다. 학습 데이터와 겹치지 않도록 한다.

#### 용어와 개념

* *예측 데이터 일 수 (pred_data_days, P_d)* : 예측에 필요한 데이터의 일 수. 학습된 군집 모델 중 적절한 것을 선택할 수 있도록 유효 데이터 일 수 (e_d)와 같게 한다.

* *예측 데이터 종료일 (pred_data_end, P_e)* : 예측 데이터의 마지막 날자. 대개 예측일 (t) 전날이다.

* *예측 데이터 시작일 (pred_data_begin, P_b)* : 예측 데이터의 시작 날자. 예측 데이터 종료일에서 예측 데이터 일 수를 뺀 것

$$P_b = P_e - P_d$$

* 예측 데이터 내 결석률이 이탈 결석률 이상인 유저는 기이탈로 판단해 예측 대상에서 제외한다.

* 학습 및 예측 데이터 기간과 예측일에는 다음과 같은 관계가 있다:

$$ L_{b} \lt L_{e} \lt P_{b} \lt P_{e} \lt t$$

#### 슈도 코드

예측 데이터를 모으는 과정의 슈도 코드는 아래와 같다:

```
예측 데이터 시작일과 종료일에서 예측 데이터 (P) 초기화
예측 데이터 내 각 유저 데이터에 대해
  유효 접속일 수 (e_p) 이상 플레이하지 않았으면:
    다음 유저로
  결석률 (a) 이 r_c 이상이면:
    기이탈로 판단해 제외
  유저의 주당 접속일 수 (k) 로 유저의 군집 결정
  선택된 군집의 모델로 예측
```
