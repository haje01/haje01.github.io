---
layout: post
title: 이탈 예측을 어떻게 할 것인가?
description:
date: 2020-02-07
tags: [ml, idea, draft]
---

예전에 게임 유저 이탈 예측을 시도해 보았는데, 성과가 썩 좋지는 않았다. 유저 이탈은 외부 요인 등으로 인해 성능에 한계가 있지만, 아래의 사항을 고려하여 다시 시도해보려 한다.

## 개선할 것

### 피처 합성 및 HPO 활용

저번에는 수작업된 피처들과, 적당한 휴리스틱으로 선택한 초모수로 훈련하였다. 최근에 [Featuretools](https://www.featuretools.com) 등의 자동 피처 합성기와 Dask / Ray 클러스터를 이용한 초모수 최적화(Hyper-parameter Optimization) 테크닉을 활용해보려 한다. 얼마 안되는 피처에서 대충 설정한 초모수 보다는 좋은 결과가 나올 것으로 기대한다.

지금부터 필자가 고안한 변수와 초모수를 이용하여 이탈 예측 방법을 설명하겠다. 초모수는 서비스별 특성에 맞게 변경이 가능할 것이다.

### 유저 플레이 빈도 고려

저번에는 매일 플레이하는 유저나, 주말에만 플레이하는 유저나 같은 모델을 사용했는데, 이 부분이 개선이 필요한 것 같다. 일반적으로 초기에는 열성적으로 매일 플레이하던 유저도 점점 접속일 간격이 벌어지면서 결국 이탈하는 경향이 있다. 반면 매일 플레이하다 갑자기 이탈하는 유저도 존재하는데, 이런 경우들을 구분해서 모델을 만들고 싶다.

구체적인 군집화 방법은 아래에서 설명할 것이다. 여기서는 군집을 다음처럼 나누고, 특성에 맞는 모델을 이용한다는 것을 이야기 해둔다.

* 군집 분류 예:
  * g^a - 단위 기간 접속일이 6, 7 일인 유저군
  * g^b - 단위 기간 접속일이 3, 4, 5 일인 유저군

* 일반적으로 g^a 군의 유저는 이탈 확률이 낮고, g^b 군의 유저는 높을 것으로 추정되며 징후도 다를 것이기에 각 군집 별로 데이터를 모으고 학습한다.
* 시간이 경과됨에 따라 유저가 속한 군집도 바뀔 것이기에, 기간 별로 유저의 군집을 평가해 사용한다.
* 위의 것은 예시이며, 이탈 검출하려는 서비스의 특성에 맞게 적당히 군집을 설정하여 사용한다.

### 유저 군집의 활용

* 유저 군집별로 학습 / 예측 데이터를 준비한다.
* 유저 군집별로 예측 모델을 학습한다.

## 용어와 개념

* *예측일 (target_day, t)* : 이탈을 예측하는 날자
* *기간 (term, T)* : 시작일 (begin, b) 부터 종료일 (end, e) 로 결정되는 범위를 지칭. 종료일 (e) 는 포함하지 않는다.
* *단위 기간* (unit_term, U) : 사용하는 기간의 기본 단위. 보통 U = 7, 즉 일주일로 한다.
* *기간 일수 (days, d)* : 기간 내 날자의 수
* *접속일 (play)* : 유저가 플레이한 날
* *결석일 (absent)* : 유저가 플레이하지 않은 날
* *마지막 접속일 (last_play, l)* : 유저의 기간 내 마지막 접속일
* *결석 일수 (absents, a)* : 유저가 기간 동안 결석한 일수
  * 기간 내 마지막 접속일에서 기간의 마지막 날까지 결석일을 센다.
  * 예로, 마지막 날 e = 2020-02-10 인 기간에서 마지막 접속일 l = 2020-02-05 로 이후 결석하고 있다면, 결석 일수 a = 4 가 된다

$$a = e - l - 1$$

* *기간 접속 일수 (plays, p)* : 기간 내 유저가 접속한 일수
  * 주어진 기간 동안 4번 접속한 경우 $p = 4$

* *단위 기간 접속 일수 (unit_plays, k)* : 기간 내 유저의 접속 일수를 단위 기간으로 계산한 것.
  * 예로, 유저가 기간 일수 d = 14 동안 접속 일수 p = 5 인 경우, 단위 기간이 일주일 U = 7 일때 단위 기간 접속 일수 k = 3
  * 이 값으로 해당 기간동안 유저의 군집을 결정하게 된다.
  * 최대값은 U 와 같다.

$$k = \lceil \frac {p} {d} \times U \rceil $$

* *단위 기간 한계 접속 일수 (unit_margin_plays, k^mar)* : 단위 기간 접속 일수 (k) 의 한계값. 유저의 단위 기간 접속일수가 이 값 미만이면 학습 및 예측에서 제외한다 (초모수).
  * 예측의 기대 이익에 맞도록 적절하게 선택

* *접속 주기 (play_freq, f)* : 유저가 몇 일마다 접속하는지의 값. 유저가 대상 기간내 접속한 첫 날과 마지막 날로 유저별 기간을 정한뒤, 그 기간 내 기간 일수 (d) 와 접속 일수 (p) 로 계산
  * 예로, 대상 기간 14 일 동안 어떤 유저의 접속 및 결석일이 다음과 같은 경우 (접속일을 0, 결석일을 1로 표시)
    * `[0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]`
  * 해당 유저의 접속 주기 계산을 위한 기간은 두 번째 날부터 여덟 번째 날까지의 7일간이다.
  * 즉, 기간 일수 d = 7 동안 접속 일수 p = 4 인 경우로, 접속 주기 f = 1.75 이 된다.

$$f =  \frac {d} {p} = \frac {U} {k} $$

* *최대 접속 주기 (max_play_freq, f^max)* : 접속 주기의 최대값. 단위 기간 (U) 및 한계 접속 일수 (k^mar) 로 계산.
  * 예로, 단위 기간 U = 7 이고 한계 접속 일수 k^mar = 3 이면, f^max = 2.33 이 된다.

$$f^{max} = \frac {U} {k^{mar}} $$

* *군집 (group, g)* : 접속 빈도에 따른 학습 데이터와 예측 모델 분류에 사용. 군집은 유저의 단위 기간 접속 일수 (k) 를 이용해, 서비스별 휴리스틱으로 정의한다. 예로, 앞에서 다음과 같이 군집을 설정하였다.
  * g^a - 단위 기간 접속일이 6, 7 일인 유저군
  * g^b - 단위 기간 접속일이 3, 4, 5 일인 유저군
  * 이때, 단위 기간 접속일이 6 일인 유저는 g^a, 3 일인 유저는 g^b 에 속하게 된다.

* *유효 접속 일수 (effect_plays, e_p)* : 군집 판정, 학습이나 예측에서 몇 개의 접속일 데이터를 사용할지를 나타냄 (초모수)
  * 예로 e_p = 4 인 경우, 군집 판정에서는 판정 시작일 부터 4 접속일의 데이터를, 이탈 예측에서는 예측일 이전 4 접속일의 데이터를 사용하겠다는 뜻이다.
  * 이 값이 클 수록 모델 성능이 향상될 수 있으나, 많은 데이터가 필요하고 개념 표류 (Concept Drifting) 가 발생할 수 있다.

* *유효 데이터 일수 (effect_data_days, e_d)* : 유저별로 유효 접속 일수에 해당하는 데이터 수집에 필요한 기간 일수.
  * 접속 주기와 유효 접속일수를 곱해 추정할 수 있으나, 실제 값은 유저별로 실제 접속일 데이터를 살펴보아야 알 수 있다.

$$\hat {e_d} = \lceil f \times e_p \rceil$$

* *최대 유효 데이터 일수 (max_effect_data_days, e_d^max)* : 모든 대상 유저의 유효 데이터 일수 중 가장 큰 값. 전체 대상 유저에 대한 유효 데이터를 확보하려할 때 사용.
  * 최대 접속 주기 (f^max) 와 유효 접속 일수 (e_p) 로 추정한다.
  * 예로, f^max = 2.33 이고 e_p = 4 인 경우, e_d^max = 10 이다. 즉, 모든 대상 유저의 유효 접속 일수 데이터 확보를 위해서는, 적어도 10 일 기간의 전체 데이터를 확보해야 한다.

$$e_d^{max} = \lceil f^{max} \times {e_p} \rceil $$

* *접속 예정일 (due_play_day, q)* : 기간 내 유저의 마지막 참석일 이후 예상되는 다음 접속일. 마지막 접속일 (l) 과 접속 주기 (f) 로 계산.

$$q = \lceil l + f \rceil$$

* *결석률 (absent_rate, r)* : 유저의 접속 예정일 (q) 부터, 예측일 (t) 까지 기간의 결석 일수를 접속 주기에 대한 비율로 나타낸 것 (0 이상).
  * 다양한 접속 주기의 유저들의 결석 정도를 일관성있게 평가하기 위한 값
  * 예로, 접속 주기 f = 2.33 일인 유저가, 6일 동안 결석했다면 (a = 6), 결석율 r = 2.57

$$r = max \left( \frac {a} {f}, 0 \right) $$

* *이탈 결석률 (churn_absent_rate, r_c)* : 유저의 결석률이 이 값보다 크거나 같으면 이탈로 판정. 오탐이나 미탐이 적도록 설정 (초모수)
  * 예로, r_c = 3 이면 세 번의 접속 주기만큼 결석하면 이탈이라는 뜻

* *이탈 판정 일수 (churn_decide_days, c_d)* : 유저의 이탈 판정에 필요한 날자 수. 이탈 결석률 (r_c) 과 접속 주기 (f) 에서 계산
  * 예로, 접속 주기 f = 1.75 인 유저에 대해 이탈 결석률 r_c = 3 으로 하면, 이탈 판정 일수 c_d = 6 로, 마지막 접속일 후 6 일이 지나야 이탈 판정이 가능하다.

$$c_d = \lceil f \times r_c \rceil $$

* *최대 이탈 판정 일수 (max_churn_decide_days, c_d^max)* : 모든 이탈 판정 일수 중 가장 큰 값. 최대 접속 주기 (f^max) 와 이탈 결석률 (r_c) 로 계산
  * 예로 최대 접속 주기 f^max = 2.33 이고 이탈 결석률 r_c = 3 이면 c_d^max = 7 이다.

$$c_d^{max} = \lceil f^{max} \times r_c \rceil $$

* *이탈 검증률 (churn_test_rate, r_t)* : 각 유저의 이탈 판정 후, 이탈 검증에 필요한 일수를 계산하기 위한 비율. 이탈 결석률에 대한 비율로, r_t = 1 이면 이탈 결석률과 같은 일수 경과 후 이탈 판정을 하게 된다. (초모수)
  * 너무 작으면 제대로된 검증을 할 수 없고, 너무 크면 검증에 시간이 오래 걸리며 지나치게 엄격한 검증이 될 수 있다.

* *이탈 검증 일수 (churn_test_days, t_d)* : 각 이탈 유저에 대해, 이탈 판정일 후 이 일수까지의 날자 경과 후 이탈 검증을 수행한다. 이탈시 접속 주기 (f), 이탈 결석률 (r_c) 및 이탈 검증률 (r_t)을 곱해 구한다.
  * 예로, 어떤 이탈자의 이탈 판정시 접속 주기가 f = 2.33 이었고, 이탈 결석률 r_c = 3, 이탈 검증률 r_t = 1 이면, 이탈 검증 일수 t_d = 7 이다
  * 즉, 이 유저의 이탈 판정일부터 7일 후까지 단위 기간 한계 접속 일수 (k^mar) 이상의 접속이 있었으면 판정 오류, 접속이 없으면 판정이 맞은 것으로 처리한다.

$$ t_d = \lceil f \times r_c \times r_t \rceil = \lceil c_d \times r_t \rceil$$

* *최대 이탈 검증 일수 (max_churn_test_days, t_d^max)* : 모든 이탈자의 이탈 검증 일수 중 가장 큰 값. 최대 접속 주기 (f^max), 이탈 결석률 (r_c) 및 이탈 검증률 (r_t) 을 곱해 구한다.
  * 이탈 검증을 위해 이 일수 만큼의 데이터를 확보해야 한다.

$$ t_d^{max} = \lceil f^{max} \times r_c \times r_t \rceil = \lceil c_d^{max} \times r_t \rceil$$

## 피처

예측 모델의 성패는 피처에 달려있다고 해도 과언이 아닐 것이다. 피처는 다양한 방식으로 발굴될 수 있는데, 이 글에서 다 다루기는 어렵다. 별도의 글 [온라인 게임을 위한 피처 유니버스 만들기](https://haje01.github.io/2020/03/17/feature-universe.html) 를 참고하도록 하자.

## 데이터 준비

앞서 말한 개념과 피처를 이용해 학습 및 예측을 위한 데이터를 준비하게 된다. 중요한 것은 *모든 유저가 대상은 아니라는 점* 이다. 게임 가입 후 적응하지 못하여 초기에 이탈했거나, 비정기적으로 플레이하는 유저, 그리고 어뷰징 툴을 사용하는 등의 유저는 *기대 이익을 최대화하는 이탈 검출* 을 위해 대상으로 하지 않는 것이 바람직할 것이다.

### 학습 데이터

*학습 데이터 (learn_data, L)* 는 유저별 *피처 (features, X)* 와 *라벨 (label, y)* 로 구성되며, 여기에서 각 군집별 학습 데이터가 만들어 진다.

#### 용어와 개념

* *학습 데이터 (learn_data, L)* : 대상 기간 (T) 에 대한 학습 데이터.
* *학습 데이터 일수 (learn_data_days, L_d)* : 기간 내 학습 데이터의 날자 수
  * 학습 데이터 일수가 많을 수록 데이터가 많아지나, 개념 표류를 피하도록 적절한 L_d 설정 (초모수)
  * 적어도 이후 설명할 한계 학습 데이터 일수 (L_d^mar) 이상이어야 한다.

$$L_d \geq L_d^{mar}$$

* *한계 학습 데이터 일수 (learn_data_margin_days, L_d^mar)* : 학습용 데이터는 군집 결정 및 이탈 판정이 가능해야하는데, 이를 위해 필요한 최소한의 데이터 날자 수.
  * 최대 유효 데이터 일수 (e_d^max) 와 최대 이탈 판정 일수 (c_d^max) 의 합이다.
  * 예로, 최대 유효 데이터 일수 e_d^max = 28 이고 최대 이탈 판정 일수 c_d^max = 14 이면 한계 학습 데이터 일수 L_d^mar 은 42 가 된다.

$$L_d^{mar} = e_d^{max} + c_d^{max}$$

> 한계 학습 데이터 일수는 어디까지나 최소한의 값이다. 이에 따라 데이터를 확보해도 그 기간동안 유저 행동에 변동이 있으면 데이터가 부족해질 수 있기에, 실제 학습 데이터 일수는 한계 학습 데이터 일수 보다 여유있게 잡자.

* *학습 데이터 시작일 (learn_data_begin, L_b)* : 학습 데이터의 시작 날자.
* *학습 데이터 종료일 (learn_data_end, L_e)* : 학습 데이터의 마지막 날자. 이어 설명할 예측 데이터 시작일 (P_b) 보다 작아야 함

$$ L_e < P_b $$

* 학습 데이터의 시작일은 학습 데이터 종료일 (L_e) 과 학습 데이터 일수 (L_d) 로 결정

$$L_b = L_e - L_d$$

#### 군집별 학습 데이터

앞에서 단위 기간 접속 일수 (k) 로 유저의 군집을 배정하는 것을 보았다. 학습 데이터는 군집 별로 따로 준비한다:

* 같은 유저도 시간 경과에 따라 접속 주기가 달라질 수 있기다. 이어 설명할 *수집 윈도우* 를 이용해 시기별 군집을 결정하고 학습 데이터를 배정한다.
* 예 : 어떤 유저가 수집 윈도우에서 단위 기간 접속일이 6 -> 4 으로 변하다 이탈
  * 이 유저의 k = 6 시기 데이터를 g^a 에 배정하고 비이탈로 라벨링
  * 이 유저의 k = 4 시기 데이터를 g^b 에 배정하고 이탈로 라벨링

* *수집 윈도우 (col_window, w)* : 유저의 학습 데이터를 순회하며 데이터를 수집하는 윈도우.
  * 데이터 양을 늘리고 시기별로 맞는 군집에 데이터를 배정하기 위해 이용

* *수집 윈도우 시작일 (col_window_begin, w_b)* : 유저에 대한 윈도우 시작일. 처음에는 유저의 기간 내 첫 접속일과 같다. 이어 설명할 윈도우 스텝만큼 증가한다.

* *수집 윈도우 크기 (col_window_width, w_w)* : 수집 윈도우의 범위.
  * 먼저 수집 윈도우 시작일부터 단위 기간 동안 유저의 접속 일수로 단위 기간 접속 일수 (k) 를 구한다.
  * k 에서, 유효 데이터 일수 (e_d) 및 이탈 판정 일수 (c_d)를 구한다. 두 값의 합이 윈도우의 크기가 된다.
  * 유효 데이터 일수의 데이터는 학습에 사용되고, 이탈 판정 일수의 데이터는 라벨링에 사용된다.

$$w_w = e_d + c_d$$

* *수집 윈도우 종료일 (col_window_end, w_e)* : 수집 윈도우 시작일 부터 유효 데이터 일수 및 이탈 판정 일수로 계산

$$w_e = w_b + w_w$$

여기까지의 설명을 그림으로 나타내면 아래와 같다:

![수집 윈도우](/assets/2020-03-18-17-42-57.png)

* *수집 윈도우 스텝 (col_window_step, w_s)* : 윈도우의 진행 크기
  * 중복을 허용하되, 적정 수준을 유지하도록 유저의 유효 데이터 일수 (e_d) 에 *윈도우 스텝 비율 (col_window_step_rate, s)* (초모수) 을 곱해 정한다.

$$ w_s = \lceil e_d \times s \rceil ; s \in \mathbb R, 0 \lt s \leq 1 $$

* 수집 윈도우는 스텝 단위로 진행하다가, 윈도우 종료일이 학습 데이터 종료일보다 커질 때 끝난다.

#### 슈도 코드

학습 데이터를 모으는 과정의 슈도 코드는 아래와 같다:

```
학습 데이터 시작일 (L_b) 과 종료일 (L_e) 에서 학습 데이터 (L) 초기화
학습 데이터 내 모든 유저에 대해
  첫 접속일을 수집 윈도우 시작일 (w_b) 로
  유효 접속일의 데이터로 수집 윈도우 크기 (w_w) 구함
  수집 윈도우에 대해
    유효 접속 일수 (e_p) 에 미치지 못하거나, 수집 윈도우 종료일 (w_e) 이 학습 데이터 종료일보다 크면
      다음 유저로
    단위 기간 접속 일수 (k) 로 군집 결정
    윈도우내 유효 데이터 일수 (e_d) 의 피처 데이터 (X) 를 군집의 학습 데이터에 추가
    윈도우내 이탈 판정 일수 (c_d) 의 결석일로 이탈 여부 (y) 를 군집의 학습 데이터에 추가
    이탈했으면
      다음 유저로
    수집 윈도우의 스텝만큼 윈도우 진행하고, 유효 접속일의 데이터로 수집 윈도우 크기 (w_w) 구함
```

위의 과정을 그림으로 나타내면 아래와 같다:

#### 학습 데이터 수집 예

지금까지 설명한 개념과 과정의 이해를 돕기 위해, 추가적인 예를 들어 설명하겠다.아래는 단위 기간 접속 일수가 k = 6 (군집 g^a) -> k = 4 (군집 g^b) 으로 변하고 이탈한 유저의 예이다.


* 공통 변수
  * 단위 기간 U = 7
  * 이탈 접속률 r_c = 3
  * 윈도우 스텝 비율 s = 0.4
  * 유효 접속 일수 e_p = 6

* 단위 기간 접속 일수 k = 6 인 경우
  * 유효 데이터 일수 e_d = 7
  * 이탈 판정 일수 c_d = 5
  * 윈도우 크기 w_w = e_d + c_d = 12
  * 윈도우 스텝 w_s = 3
  * 군집 a

* 단위 기간 접속 일수 k = 4 인 경우
  * 유효 데이터 일수 e_d = 11
  * 이탈 판정 일수 c_d = 6
  * 윈도우 크기 w_w = e_d + c_d = 17
  * 윈도우 스텝 w_s = 5
  * 군집 b

![수집 과정](/assets/2020-03-18-17-51-44.png)

### 초모수의 선택

여기서는 초모수를 정하는 예를 살펴보겠다. 온라인 및 모바일 게임 서비스이고 단위 기간을 일주일로 할 때, 다음과 같이 초모수를 선택한다:

* 유효 접속 일수 (e_p)
  * 4 ~ 10 범위에서 예측 점수가 높은 것을 HPO로 선택

* 단위 기간 한계 접속 일수 (k^mar) = 3
  * 일주일에 세 번 오는 유저까지를 대상. 너무 가끔씩 접속하는 유저는 예측의 효용성이 작을 수 있다.

* 이탈 결석률 (r_c)
  * 학습 데이터에서 이탈 검증 일수 (t_d) 및 이탈 검증률 (r_t) 로 판정 오류를 조사하고,
  * 3~10 범위에서 에러율이 작은 것을 HPO로 선택한다.

* 학습 데이터 일수 (L_d)
  * 60 일로 한다.

* 윈도우 스텝 비율 (s)
  * 0.4 으로 한다.

> 어떤 서비스에서 어떤 척도를 사용하는지에 따라 다양한 초모수가 이용될 수 있겠다.

#### 척도의 선택

> 실제 예측 모델이 목표로 해야할 것은 오차를 최소화하는 것이 아니라 모델 적용을 통해 기대되는 이익을 최대화 하는 것
>
> [실전 이탈 예측 모델링을 위한 세 가지 고려 사항](https://brunch.co.kr/@gimmesilver/53) 에서

흔히 사용되는 Accuracy, Recall, F1-Score 등의 척도의 선택도 *이익을 최대화* 하기 위한 방향으로 하는 것이 맞을 것이다.

예를 들어 제한된 프로모션 비용에서 이익의 최대화 하기 위해서 VIP 대상 이탈 예측을 선택할 수 있다. 이들은 결제를 유발할 수 있는 진성 유저들이기에 오탐을 두려워하지 말고 미탐이 적은 방향으로 학습 척도를 선택할 수 있겠다.

#### 학습 진행

군집별 학습 데이터에서 군집별 예측 모델을 학습한다. 학습 과정의 슈도 코드는 아래와 같다:

```
각 군집에 대해:
  군집 모델 초기화
  군집별 학습 데이터에 대해:
    피처 데이터 (X) 및 라벨 (y) 을 이용해 대해 척도 기준으로 학습
```

## 예측

### 예측 데이터

학습이 완료된 모델로 실제 예측을 실시한다. 이때 예측을 위한 데이터가 필요하다.

*예측 데이터 (pred_data, P)* : 기간 내 피처 데이터 (X) 로 구성되며, 유저의 이탈 여부를 예측하는데 사용된다.

#### 용어와 개념

* *예측 데이터 일수 (pred_data_days, P_d)* : 유저별 이탈 예측에 필요한 데이터의 일수. 학습된 군집 모델 중 적절한 것을 선택할 수 있도록 유효 데이터 일수 (e_d)와 같게 한다.

$$P_d = e_d$$

* *예측 데이터 종료일 (pred_data_end, P_e)* : 예측 데이터의 마지막 날자. 대개 예측일 (t) 전날이다.

* *예측 데이터 시작일 (pred_data_begin, P_b)* : 예측 데이터의 시작 날자. 예측 데이터 종료일에서 예측 데이터 일수를 뺀 것

$$P_b = P_e - P_d$$

* 예측 데이터 내 결석률이 이탈 결석률 이상인 유저는 기이탈로 판단해 예측 대상에서 제외한다.

> 예측 데이터는 학습 데이터와 겹치지 않아야 한다. 학습 및 예측 데이터 기간과 예측일에는 다음과 같은 관계가 있다:
>
> $$ L_{b} \lt L_{e} \lt P_{b} \lt P_{e} \lt t$$

#### 슈도 코드

예측 데이터를 모으는 과정의 슈도 코드는 아래와 같다:

```
예측 데이터 시작일과 종료일에서 예측 데이터 (P) 초기화
예측 데이터 내 모든 유저에 대해
  총 접속일이 유효 접속 일수 (e_p) 에 미치지 못하면
    다음 유저로
  결석률 (a) 이 이탈 결석률 (r_c) 이상이면
    다음 유저로
  유저의 윈도우의 단위 기간 접속 일수 (k) 로 군집 결정 (g^k)
  선택된 군집의 모델 (m^k) 로 이탈 여부 예측
```

## 끝으로

여기에 제시된 방법이 절대적인 것은 아닐지라도 이탈 예측을 하기 위한 참고가 되기를 바란다.
